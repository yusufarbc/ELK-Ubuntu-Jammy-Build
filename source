ORTA ÖLÇEKLİ İŞLETMELER İÇİN (100
GB/GÜN) ROCKY LINUX ÜZERİNDE
DOCKER İLE AJAN KULLANILMAYAN
ELASTIC STACK SIEM MİMARİSİ VE
OPTİMİZASYONU
1. Giriş ve Proje Özeti
Bu teknik rapor, günlük 50 ila 100 GB arasında log hacmi üreten orta ölçekli bir işletmenin
ihtiyaç duyduğu, Rocky Linux üzerinde Docker konteyner mimarisi kullanılarak inşa edilmiş,
stabil ve ajan kullanılmayan (agentless) Elastic Stack (SIEM) kurulumunu detaylandırmaktadır.
Projenin temel kısıtlaması, Elastic Stack’in ücretsiz sunulan Basic lisans sürümünün
kullanılmasıdır. Bu mimari, Windows Olay İletimi (WEF), genel Syslog ve Kaspersky Endpoint
Security (KES) loglarını merkezi olarak toplayarak temel güvenlik görünürlüğü ve alarm
mekanizmaları sağlamayı amaçlamaktadır.
1.1. Proje Kapsamı ve Basic Lisansın Stratejik Konumu
Basic lisans, Elastic Stack’in temel bileşenlerinin (Elasticsearch, Logstash, Kibana) en güncel
ve kararlı sürümlerini kullanma imkanı sunar. Operasyonel devamlılık için kritik olan Stack
Monitoring ve Veri Yaşam Döngüsü Yönetimi (Index Lifecycle Management - ILM) gibi
özelliklere erişim, Basic lisans kapsamında mümkündür.1
Ancak, Basic lisansın stratejik konumu, gelişmiş güvenlik otomasyonlarından feragat edilmesini
gerektirir. Platinum veya Gold lisanslarla gelen otomatik tehdit algılama motoru (Detection
Engine), makine öğrenimi (ML) özellikleri ve otomasyon bağlantıları (Action/Connector)
kullanılamaz. Dolayısıyla, güvenlik alarmları ve tehdit tespiti, büyük ölçüde Kibana Query
Language (KQL) 2 tabanlı sorgulamalar ve analistlerin manuel incelemesi üzerine kurulmalıdır.
İlk kurulum sırasında varsayılan olarak etkinleştirilen 30 günlük Platinum deneme süresi
sonunda, sistem otomatik olarak ücretsiz (Basic) özelliklere dönecek ve bu geçiş sırasında
herhangi bir manuel müdahale veya veri kaybı yaşanmayacaktır.3
1.2. Rocky Linux, Docker ve Ajan Kullanılmayan Mimarinin Gerekçesi
Rocky Linux, kurumsal düzeyde stabilite ve güvenlik sunan, Red Hat Enterprise Linux (RHEL)
tabanlı bir işletim sistemidir. Docker konteyner mimarisinin seçilmesi, Elastic Stack
bileşenlerinin kurulum, dağıtım ve sürüm yönetimini büyük ölçüde basitleştirir. docker-elk
şablonunun kullanılmasıyla 3, bileşenler arası entegrasyon kolaylıkla sağlanır ve kaynak
izolasyonu güçlenir.
Ajan kullanılmayan (agentless) log toplama yaklaşımı, son noktalara (endpoint) Filebeat veya
Elastic Agent gibi ek yazılımların kurulumu ve yönetimi zorunluluğunu ortadan kaldırır. Bu
yaklaşım, Windows ortamlarında merkezi bir toplama katmanını (Windows Event Collector -
WEC) 4 ve Logstash'i ana omurga yapar. WEC, Windows Olay İletimi (WEF) mekanizmasını
kullanarak tüm logları merkezi olarak toplar ve Logstash'e iletir.5 Bu tasarım, 100 GB/gün
hacmindeki log yükünün tek bir noktada yönetilmesini zorunlu kılar.
2. Mimarinin Boyutlandırılması ve Kapasite Planlaması
(100 GB/Gün)
Günlük 50-100 GB log hacmi, Elastic Stack için orta-yüksek bir hacmi temsil eder ve stabiliteyi
sağlamak için boyutlandırma planlaması kritik öneme sahiptir. Yüksek istikrar talep
edildiğinden, donanım kaynaklarından ödün verilmemelidir.
2.1. Donanım Gereksinimleri ve Elasticsearch Optimizasyonu
Günlük 100 GB log verisinin indeksleme sonrası replikasyon, dizinleme ve ek yüklerle birlikte
günlük 120-150 GB disk kullanımına ulaşması beklenir. Bu hacim, 90 günlük saklama süresi için
yaklaşık 4.5 TB brüt depolama alanı gerektirir.
Elastic topluluk tartışmaları, bu veri hacimlerinin tek bir düğümde bile ciddi kaynak talebi
doğurduğunu göstermektedir.6 Veri alımı (ingest) ve sorgu performansının aynı anda istikrarlı
çalışması için aşağıdaki minimum tek düğüm konfigürasyonu zorunludur:
1. Bellek (RAM): Elasticsearch'ün hızlı çalışması, RAM'in disk önbelleği (filesystem cache)
olarak kullanılmasına bağlıdır. 100 GB/gün veri hacmini desteklemek için minimum 64 GB
RAM önerilmektedir.
2. JVM Heap Tahsisi: Toplam RAM'in yaklaşık %50'si (32 GB) Elasticsearch'ün Java Sanal
Makinesi (JVM) Heap'ine tahsis edilmelidir (ES_JAVA_OPTS). Geriye kalan 32 GB, işletim
sisteminin disk önbelleği (filesystem cache) için serbest bırakılır ki bu, disk I/O hızını
artırarak performansı maksimize eder.
3. Depolama Tipi (I/O Hızı): 100 GB/gün hacimde, disk I/O hızı hızla darboğaz haline gelir.
İstikrarlı ve hızlı indeksleme için standart SAS SSD veya SATA SSD'ler yetersiz kalacaktır.
NVMe SSD kullanımı, özellikle konteynerleştirilmiş bir ortamda yüksek IOPS (Saniyede
Giriş/Çıkış İşlemi) sağlamak için kesinlikle zorunludur.
Minimum Üretim Donanım Özellikleri
Bileşen Önerilen RAM Önerilen CPU
(vCPU)
Depolama Tipi ve
Boyutu (1 Aylık
Saklama)
Önemli Not
Elasticsearch (Tek
Node - Minimum)
64 GB (32 GB
Heap)
12 6 TB NVMe SSD
(RAID 1/10)
Yüksek IOPS
zorunludur, disk
önbelleği için bol
RAM
Logstash 8 GB (4 GB Heap) 4 Küçük SSD Parsing yoğunluğu
nedeniyle
CPU/RAM
dengelemesi
önemlidir
Kibana 4 GB 2 Küçük SSD
Toplam Minimum
Kaynak
76 GB+ 18 vCPU+ NVMe
Zorunluluğu
2.2. Mimari Riskler ve Performans Dengesi
Tek Düğüm (Single Node) Risk Yönetimi
Günlük 100 GB veri hacmi, Elastic'in genellikle önerdiği tek düğüm sınırına yakındır. Bu, maliyet
kısıtlamaları nedeniyle (Basic lisans, tek sunucu) zorunlu olarak tek düğüm mimarisini
getirmektedir. Bu yüksek hacimde tek bir düğümde meydana gelebilecek bir JVM hatası veya
donanım arızası, tüm SIEM hizmetinin kesintiye uğraması anlamına gelir. Bu nedenle, talep
edilen stabiliteyi sağlamak için, Elasticsearch'ün kritik olarak fazla RAM (64 GB) ve mümkün
olan en hızlı depolama (NVMe) ile beslenmesi, bu tek başarısızlık noktasının (SPOF) etkilerini
en aza indirmek için gereklidir.
Logstash İş Yükünün Etkisi
Ajan kullanılmayan log toplama yaklaşımı (WEF/WEC ve Syslog) benimsendiğinde, tüm veri
toplama, ayrıştırma ve standardizasyon yükü Logstash üzerine biner. Özellikle standart Syslog
7 ve KES loglarının Grok filtreleri ile ayrıştırılması 8 ciddi CPU yükü oluşturur. Logstash'in yeterli
kaynak (en az 8 GB RAM ve 4 vCPU) ile çalıştırılması ve mümkünse Elasticsearch'ten ayrı bir
konteyner veya sanal makine üzerinde tutulması, Logstash'in yoğun parsing taleplerinin, ana
indeksleme ve sorgulama hizmeti olan Elasticsearch'ün stabilitesini olumsuz etkilemesini önler.
3. Konteynerize Elastic Stack Kurulum Rehberi (Rocky
Linux Üzerinde)
3.1. Rocky Linux Ön Hazırlık ve Docker Kurulumu
Elasticsearch’ün konteyner içinde stabil çalışabilmesi için işletim sistemi düzeyinde bazı
ayarlamalar yapılması zorunludur.
1. Sistem Sınırlarının Artırılması: Elasticsearch, çok sayıda sanal bellek haritası (virtual
memory maps) gerektirir. Konteyner başlamadan önce Rocky Linux çekirdek parametresi
yükseltilmelidir:
Bash
sudo sysctl -w vm.max_map_count=262144
echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
2. Docker ve Docker Compose Kurulumu: Rocky Linux'a standart yöntemlerle Docker
Engine ve Docker Compose (veya Docker Compose CLI) kurulmalıdır.
3.2. Docker Compose ve Temel Yapılandırma
Bu mimaride, Elastic Stack'in dağıtımı için deviantony/docker-elk projesi, Basic lisans
gereksinimlerini karşılaması ve minimal yapılandırma sunması nedeniyle en uygun başlangıç
noktasıdır.3
Lisans ve Sürüm Yönetimi
Proje varsayılan olarak Elastic’in resmi Docker imajlarını kullanır: Elasticsearch, Logstash ve
Kibana. İlk çalıştırmada, Platinum özellikler 30 günlük bir deneme süresi için etkinleştirilir. Bu
deneme süresi bittiğinde, sistem otomatik olarak kesintisiz ve veri kaybı olmaksızın Basic
(Ücretsiz) lisans özelliklerini kullanmaya devam eder.3 Kullanıcının bu geçiş için manuel
müdahaleye ihtiyacı yoktur. Ancak, bu süre içinde kurulan gelişmiş otomasyon tabanlı güvenlik
kurallarının (Detection Engine) devre dışı kalacağı unutulmamalıdır.
Konteyner Kaynak ve JVM Ayarları
docker-compose.yml dosyasında, boyutlandırma analizi (Bölüm 2) doğrultusunda her bileşen
için kaynak kısıtlamaları ve özellikle Elasticsearch için JVM Heap tahsisi belirlenmelidir:
YAML
# Örnek docker-compose.yml kesiti
services:
elasticsearch:
image: elasticsearch:${ELK_VERSION}
#... diğer ayarlar...
environment:
# 32 GB Heap tahsisi (toplam 64 GB RAM varsayımıyla)
- "ES_JAVA_OPTS=-Xms32g -Xmx32g"
# Kaynak kısıtlamaları (64 GB RAM ve 12 CPU limitleri)
deploy:
resources:
limits:
memory: 64G
cpus: '12.0'
logstash:
image: logstash:${ELK_VERSION}
#... diğer ayarlar...
environment:
# 4 GB Heap tahsisi (toplam 8 GB RAM varsayımıyla)
- "LS_JAVA_OPTS=-Xms4g -Xmx4g"
deploy:
resources:
limits:
memory: 8G
cpus: '4.0'
3.3. Kalıcı Depolama ve Ağ Ayarları
Persistent Volumes (Kalıcı Hacimler)
Tüm Elastic verileri, konteyner yeniden başlatmalarında veya versiyon yükseltmelerinde
korunmalıdır. Bu, Elasticsearch veri dizinlerinin ve Logstash yapılandırma dosyalarının kalıcı
hacimler üzerine eşlenmesiyle sağlanır. Depolama altyapısı olarak NVMe diskin kullanıldığı
Rocky Linux ana sunucusundaki hızlı diskler eşlenmelidir.
Yüksek I/O gereksinimi olan 100 GB/gün log hacminde, konteynerlerin depolama katmanında
gecikme olmaması hayati önem taşır. Konteyner Depolama Arayüzü (CSI) veya yerel sürücüler
kullanılarak konteynerin NVMe diske doğrudan erişiminin sağlanması, Docker'ın varsayılan
depolama sürücülerinin neden olabileceği potansiyel I/O gecikmelerini önler ve fiziksel disk
hızının konteynere yansımasını garantiler.
Ağ Yapılandırması
Logstash konteyneri, farklı ajan kullanılmayan log kaynaklarını dinlemek üzere ayarlanmalıdır:
● WEF/WEC (Windows Olayları): TCP/5044 (Örnek)
● Genel Syslog (Ağ Cihazları, Linux): UDP/TCP 514
● KES Olayları: TCP/1514 (Özel port)
Bu portların Rocky Linux güvenlik duvarında (firewall) açılması ve Docker ağında doğru şekilde
yayınlanması gerekir.
4. Ajan Kullanılmayan Veri Toplama Merkezi (Logstash)
Logstash, Elastic Stack mimarisinin ayrıştırma, zenginleştirme ve yönlendirme katmanıdır.
Stabilite ve standartizasyon için Logstash pipeline'larının optimize edilmesi zorunludur.
4.1. Elastic Common Schema (ECS) Uyumluluğu
Elastic Common Schema (ECS), farklı kaynaklardan gelen olay verilerini (örneğin Windows
olayları, Syslog, KES olayları) normalize etmek için kullanılan açık kaynaklı bir spesifikasyondur.9
ECS kullanımı, verilerin Kibana’daki SIEM uygulaması içinde tutarlı bir şekilde aranmasını,
görselleştirilmesini ve olayların ilişkilendirilmesini sağlar. Örneğin, tüm kaynak IP adresleri
source.ip alanına eşlenir.8
Logstash 8 ve üzeri sürümlerde ECS uyumluluğu varsayılan olarak v8 modunda çalışır.8 Bu
durum, varsayılan plugin davranışlarını ECS ile uyumlu hale getirir, ancak Grok filtreleri ile
ayrıştırılan Syslog ve KES gibi loglar için kritik alanların ECS standartlarına
manuel olarak eşlenmesi gereklidir.
4.2. Logstash Pipeline Mimarisi ve ILM Entegrasyonu
Performans ve hata izolasyonu için, farklı log türleri (WEF, Syslog, KES) için ayrı Logstash
pipeline'ları oluşturulması ve bu pipeline'ların farklı ECS uyumlu indeks şablonlarına çıktı
vermesi önerilir.
Veri Yaşam Döngüsü Yönetimi (ILM)
Günlük 100 GB veri hacminde, indekslerin boyutları hızla büyür. ILM'nin doğru uygulanması,
sorgu performansını korumak ve disk alanını yönetmek için zorunludur.1 Basic lisans, ILM'nin
Hot, Warm ve Delete aşamalarını destekler.
ILM politikasında, performans düşüşünü önlemek için indekslerin devredilme (rollover) şartları
belirlenmelidir:
● Rollover Şartları: İndeksler, maksimum 50 GB boyutuna ulaştığında veya 30 gün yaşını
doldurduğunda devredilmelidir.1 100 GB/gün hacmi, 50 GB boyut şartının hızlıca
(genellikle her 12-24 saatte bir) tetikleneceğini gösterir. ILM kullanılmazsa, devasa
indeksler sorgu gecikmelerine ve küme istikrarsızlığına neden olur.
Logstash çıktı aşamasında, her log türü için bu ILM politikasını içeren özel bir indeks şablonu
(index template) tanımlanmalıdır.
Logstash Input, Filter ve ILM Politikaları
Log Kaynağı Logstash Girişi
(Input)
Filtre Tipi Hedef Index
Şablonu
Kritik ECS Alanı
Örneği
WEF/WEC
(Windows
Olayları)
TCP (5044) json veya xml logs-windows-eve
nts-000001
winlog.event_data.
TargetUserName,
event.code
Genel Syslog (Ağ
Cihazları)
UDP/TCP (514) grok
(Standart/Custom)
logs-network-000
001
source.ip,
destination.ip,
log.original
KES Olayları
(Syslog
Üzerinden)
TCP (1514) grok (Özel KES) logs-kaspersky-0
00001
host.name,
kaspersky.event.id
, user.name
4.3. Logstash Performans Optimizasyonu
Yüksek hacimli veri akışında Grok filtrelerinin yoğun kullanımı, Logstash'in CPU tüketimini aşırı
artırabilir ve veri alımında gecikmelere yol açabilir.7 Bu riski azaltmak için:
1. Yapılandırılmış Veri Tercihi: Windows Olay İletimi (WEF/WEC) verilerinin, Logstash’in
Grok filtresi kullanmasını gerektiren düz metin yerine, mümkün olduğunca JSON veya
XML gibi yapılandırılmış bir formatta alınması, Logstash performansını radikal şekilde
iyileştirir ve parsing hatalarını azaltır.
2. Verimli Grok Kullanımı: Syslog ve KES logları için Grok kaçınılmazsa, desenler
olabildiğince spesifik ve hızlı eşleşecek şekilde yazılmalı, gereksiz ayrıştırmalardan
kaçınılmalıdır.
5. Windows Olay İletimi (WEF/WEC) Entegrasyonu
Ajan kullanılmayan mimaride Windows loglarının toplanması, Windows Event Collector (WEC)
sunucusunun doğru yapılandırılmasına bağlıdır.
5.1. WEC Sunucusunun Rolü
WEC sunucusu, son noktalara ajan (Winlogbeat) kurma zorunluluğunu ortadan kaldırır.
İstemciler (WEF Client), Yerel Grup İlkesi (GPO) kullanılarak etkinleştirilen yerleşik iletme
istemcisi aracılığıyla olayları WEC sunucusuna iletir.4 Logstash konteyneri, sadece bu merkezi
WEC sunucusunu dinler. Bu, tüm Windows loglarının tek bir, kontrol edilebilir bir akış üzerinden
gelmesini sağlar.
5.2. Grup İlkesi (GPO) ve WEF İstemcilerinin Yapılandırılması
1. GPO İle Abonelik URL'si Yayımlama: GPO, WEF istemcilerine, WEC sunucusu üzerinde
tanımlı olan aboneliklerin (Subscription) listesini içeren WSman URL'sini yayımlar.5 Bu
URL'lerin AD grup izinleriyle korunması, yetkisiz cihazların aboneliklere erişimini engeller.
2. Abonelik (Subscription) Tanımlama: WEC sunucusu üzerinde, toplanacak olayları
(örneğin kritik güvenlik olayları: 4624, 4625, 4776, vb.) ve bu olayların hangi istemcilerden
(AD grupları temelinde) seçileceğini belirleyen abonelikler oluşturulur.4
WEC sunucusu, log pipeline'ının kritik tek başarısızlık noktasıdır (SPOF). Yüksek erişilebilirlik
(HA) gerekiyorsa, GPO'ya birden fazla WSman abonelik URL'si eklenerek yedekli WEC
sunucuları kurulabilir ve stabilite artırılabilir.5
5.3. Logstash ile WEC Çıktısının Alınması ve İşlenmesi
WEC, olayları Logstash'e bir TCP dinleyicisi (örneğin 5044) üzerinden iletir. Logstash, GPO ve
WEC abonelikleri aracılığıyla JSON veya XML formatında yapılandırılmış veriyi almayı
hedeflemelidir.
Ruby
# Logstash Input (WEF/WEC)
input {
tcp {
port => 5044
codec => json # WEC çıktısı JSON olarak yapılandırılmışsa
type => "windows"
}
}
filter {
# Eğer JSON formatında geliyorsa, sadece ECS alanlarına taşıma yapılır
mutate {
rename => { "[winlog][event_id]" => "[event][code]" }
rename => { "" => "[source][ip]" }
# Diğer gerekli ECS eşlemeleri...
}
}
Bu yöntemin kullanılması, Grok filtresine kıyasla yüksek hacimli 100 GB/gün log trafiğinde
Logstash'i çok daha az yoracaktır.
6. Çeşitli Kaynaklardan Log Toplama ve
Standardizasyon
6.1. Genel Syslog Toplama (Ağ Cihazları, Linux Sunucular)
Logstash, ağ cihazları ve Linux sunucularından gelen Syslog mesajlarını, standart UDP/TCP 514
portları üzerinden dinlemelidir. Genel Syslog verisi, genellikle standartlaştırılmamış formatta
geldiği için Grok filtreleri kaçınılmazdır.7 Yüksek hacimli akışlarda performansı korumak için
Grok filtreleri sadece kritik alanları ayrıştıracak şekilde optimize edilmelidir.
6.2. SMB/Dosya Paylaşımı Loglama Stratejisi
Kullanıcı talebindeki ajan kullanılmama kısıtlaması nedeniyle, SMB veya dosya paylaşımlarından
doğrudan dosya tabanlı log toplamak (örneğin Logstash’in bir dizini sürekli izlemesi), 100
GB/gün hacminde zamanlama ve stabilite açısından istikrarlı bir çözüm sunmaz ve önerilmez.
Dosya tabanlı loglar için en iyi ajan kullanılmayan strateji, log üreten uygulamanın veya
sunucunun bu logları (Winlogbeat yerine) merkezi bir Syslog sunucusuna (Logstash) iletmek
üzere yapılandırılmasıdır.
6.3. Kaspersky Endpoint Security (KES) Log Entegrasyonu
Kaspersky, olaylarını harici SIEM sistemlerine aktarma yeteneğine sahiptir.10 KES olaylarının
manuel olarak CSV dosyasına aktarılması yöntemi, 5000 kayıt sınırı nedeniyle 10 100 GB/gün
hacminde kullanışsız ve yetersizdir.
En stabil ajan kullanılmayan yöntem, KES Yönetim Konsolu'nun güvenlik olaylarını
yapılandırılmış Syslog mesajları olarak Logstash'e (Örn: TCP/1514) iletmesidir.
KES logları, endpoint güvenliği olaylarını temsil ettiği için, doğru ECS eşlemesi hayati önem
taşır. KES'ten alınan Syslog çıktısı için özel bir Grok deseni oluşturularak, KES'e özgü alanlar
(kaspersky.event.id, threat.name, vb.) ECS alanlarına (örneğin threat.id, user.name) doğru
şekilde eşlenmelidir. Bu Grok deseni, kurulum aşamasında Grok Debugger gibi araçlar
kullanılarak titizlikle test edilmelidir.7
7. Temel Güvenlik İzleme ve KQL Alarmları
Basic lisans, otomatik olarak tetiklenen kural motoru (Detection Engine) ve otomasyon
bağlantılarını desteklemediği için 2, güvenlik izleme stratejisi, analistin Kibana arayüzündeki
Security uygulaması içinde Kibana Query Language (KQL) tabanlı güçlü sorgulamalarına
dayanmalıdır.
7.1. KQL'in Merkezi Rolü
KQL, Elasticsearch verilerini hızlı ve etkili bir şekilde sorgulamak için tasarlanmıştır. ECS
sayesinde, farklı kaynaklardan gelen olaylar tutarlı alanlar üzerinden sorgulanabilir.
7.2. Kritik Güvenlik Olayları İçin KQL Tabanlı Kurallar
Basic lisans ile alarm üretme mekanizması, kaydedilmiş KQL sorgularının (Saved Searches)
analist tarafından periyodik olarak incelenmesi veya harici bir betik tarafından eşik aşımlarının
kontrol edilmesi üzerine kurulmalıdır.
Örnek Kural 1: Başarısız Oturum Açma Tespiti
Başarısız oturum açma girişimleri (Brute Force vektörü), Windows Olay Kimliği 4625 ile temsil
edilir.11
KQL Kuralı:
Code snippet
event.code:4625 AND NOT user.name:"Guest" AND winlog.logon.type:3
● Açıklama: Bu sorgu, devre dışı bırakılmış "Guest" hesabı dışındaki kullanıcıların, özellikle
ağ üzerinden (winlog.logon.type:3) başarısız oturum açma denemelerini tespit eder.11 Bu,
MITRE ATT&CK T1110 (Kaba Kuvvet) tekniğiyle ilişkilendirilebilir.
Örnek Kural 2: Kritik KES Uyarısı Tespiti
KES'ten gelen Syslog olaylarını izlemek.
KQL Kuralı:
Code snippet
logs-kaspersky-* AND threat.severity:Critical
● Açıklama: KES logları içindeki kritik şiddetteki tehdit tespitlerini izler.
Örnek Kural 3: Şüpheli PowerShell Komutları
Eğer WEF/WEC, detaylı işlem oluşturma loglarını (4688) topluyorsa, saldırganların sıkça
kullandığı kod çalıştırma teknikleri tespit edilebilir.
KQL Kuralı:
Code snippet
event.code:4688 AND process.name:"powershell.exe" AND process.command_line:("IEX" OR
"EncodedCommand")
● MITRE ATT&CK İlişkisi: KQL kural sonuçlarının MITRE ATT&CK Taktikleri, Teknikleri ve
Prosedürleri (TTP) ile ilişkilendirilmesi, Basic lisans ortamındaki analiste dahi kritik
bağlam sağlar.12 Bu, tespit edilen olayın hangi saldırı aşamasına (örneğin T1059 Komut
ve Scripting) ait olduğunu anlamaya yardımcı olur.
Güvenlik Amacı Kritik Olay ID /
Açıklama
Örnek KQL
Sorgusu (ECS
Alanlarını
Kullanarak)
MITRE ATT&CK
İlişkisi
Basic Lisans
Eylem (Action)
Başarısız Oturum
Açma Eşiği
Windows 4625 (Ağ
Girişi) 11
event.code:4625
AND
winlog.logon.type:
3 AND NOT
user.name:"Guest"
T1110 (Kaba
Kuvvet)
Saved Search +
Manuel İnceleme
Şüpheli Uygulama
Başlatma
Windows 4688
(Yeni İşlem
Oluşturma)
event.code:4688
AND
process.parent.na
me:"cmd.exe"
AND
process.name:("p
owershell.exe" OR
"wscript.exe")
T1059 (Komut ve
Scripting)
Saved Search +
Manuel İnceleme
Yüksek KES Tehdit
Tespiti
KES custom
Syslog Event ID
logs-kaspersky-*
AND
threat.severity:Crit
ical
T1566 veya T1059 Saved Search +
Manuel İnceleme
8. Operasyonel Yönetim ve Bakım
8.1. Index Lifecycle Management (ILM) Detaylı Uygulama
ILM politikası, disk alanını serbest bırakmak ve arama performansını en üst düzeye çıkarmak
için kritiktir.1
1. Hot Phase (Sıcak Aşama): Verinin yazıldığı ve en yoğun sorgulandığı aşama. Rollover,
performans nedeniyle 50 GB boyut sınırına veya 30 gün yaş sınırına ulaştığında
gerçekleşmelidir.1 Bu, 100 GB/gün log hacmi için indekslerin çok sık (günlük)
devredilmesi anlamına gelir, ancak bu, sorgu hızını garanti altına alır.
2. Warm/Delete Phase (Ilık/Silme Aşama): Tek düğümlü mimaride Warm aşaması, veriyi
sadece okumaya açık hale getirerek kaynak tüketimini azaltır. Delete aşaması, verilerin
belirlenen tutma süresinin (örneğin 90 gün) sonunda sistemden kalıcı olarak silinmesini
sağlar.
8.2. Bakım, Yedekleme ve Stabilite
Basic lisans, resmi bir teknik destek (SLA) içermez. Bu nedenle, operasyonel stabilite tamamen
doğru boyutlandırma, ILM yönetimi ve proaktif sistem bakımına bağlıdır. Kurulum mimarisinin
aşırı sağlam (64 GB RAM, NVMe) olması, harici desteğin yokluğunu telafi etmelidir.
1. Snapshot Yönetimi: Konteyner verilerinin (özellikle Elasticsearch kalıcı hacimleri 3)
kurtarılması için, verilerin periyodik olarak harici bir depolama birimine (Amazon S3,
MinIO, veya SMB paylaşımı) anlık görüntüsü (Snapshot) alınmalıdır.
2. Konteyner Sağlık Kontrolü: Docker’ın otomatik yeniden başlatma politikaları (restart
policies) kullanılmalı ve konteynerlerin sağlıklı çalıştığını doğrulamak için periyodik sağlık
kontrolleri yapılandırılmalıdır.
Sonuç ve Öneriler
Bu rapor, orta ölçekli bir işletmenin 100 GB/gün log hacmi gereksinimini Rocky Linux üzerinde
Docker mimarisi ve Basic lisans kısıtlamaları altında stabil bir şekilde karşılayabilecek bir Elastic
Stack SIEM mimarisini detaylandırmıştır. Ajan kullanılmayan log toplama stratejisi (WEF/WEC,
Syslog, KES Syslog) Logstash’e ciddi bir ayrıştırma yükü getirir; bu nedenle NVMe disk ve 64
GB RAM gibi yüksek kaynak tahsisi zorunludur.
Başarılı bir Basic SIEM operasyonu için temel başarı faktörleri şunlardır:
1. Performans Garantisi: Tek düğümlü mimaride, kritik olarak yüksek RAM ve NVMe
depolama kullanımı, stabil veri alımının (ingestion) ön koşuludur.
2. Standardizasyon: Tüm logların (özellikle KES ve WEF/WEC) Grok yerine yapılandırılmış
formatlar tercih edilerek ECS standardına tam olarak uyarlanması.8
3. Operasyonel Süreklilik: ILM politikalarının 50 GB/shard devir kuralıyla hızlı hacim
artışına uyarlanması ve kalıcı yedekleme (snapshot) stratejisinin uygulanması.1
4. Güvenlik Algılaması: Otomatik otomasyon eksikliği nedeniyle, analistin yetkinliğine
yatırım yapılmalı ve kritik tehditler için ECS tabanlı KQL sorguları ve MITRE ATT&CK
eşlemeleri hazırlanmalıdır.12
Bu mimari, maliyet etkin bir şekilde log toplama ve temel tehdit görünürlüğü sağlar. Gelecekte,
eğer kurum daha gelişmiş otomatik tehdit tespiti ve yanıt yetenekleri (örneğin, tam otomasyon
ve makine öğrenimi) talep ederse, Gold veya Platinum lisans seviyelerine geçiş önerilir.
Works cited
1. Configure a lifecycle policy | Elastic Docs, accessed on October 3, 2025,
https://www.elastic.co/docs/manage-data/lifecycle/index-lifecycle-management/
configure-lifecycle-policy
2. KQL | Elastic Docs, accessed on October 3, 2025,
https://www.elastic.co/docs/explore-analyze/query-filter/languages/kql
3. deviantony/docker-elk: The Elastic stack (ELK) powered by ... - GitHub, accessed
on October 3, 2025, https://github.com/deviantony/docker-elk
4. Use Windows Event Forwarding to help with intrusion detection - Microsoft Learn,
accessed on October 3, 2025,
https://learn.microsoft.com/en-us/windows/security/operating-system-security/d
evice-management/use-windows-event-forwarding-to-assist-in-intrusion-detec
tion
5. Ingest Windows Event Logs via WEC & WEF | Elastic Blog, accessed on October 3,
2025,
https://www.elastic.co/blog/the-essentials-of-central-log-collection-with-wef-w
ec
6. What Hardware do I need for 100 GB Per day data volume? - Elasticsearch -
Elastic Discuss, accessed on October 3, 2025,
https://discuss.elastic.co/t/what-hardware-do-i-need-for-100-gb-per-day-data-
volume/138397
7. Logstash configuration examples - Elastic, accessed on October 3, 2025,
https://www.elastic.co/docs/reference/logstash/config-examples
8. ECS in Logstash - Elastic, accessed on October 3, 2025,
https://www.elastic.co/docs/reference/logstash/ecs-ls
9. Conventions | ECS reference - Elastic, accessed on October 3, 2025,
https://www.elastic.co/docs/reference/ecs/ecs-conventions
10. Exporting the event log - Kaspersky Support, accessed on October 3, 2025,
https://support.kaspersky.com/ksmg/207722
11. Olay 4625 - Bir hesap oturum açamadı. Misafir olarak mı görünüyor? :
r/cybersecurity, accessed on October 3, 2025,
https://www.reddit.com/r/cybersecurity/comments/wltce3/event_4625_an_accoun
t_failed_to_log_on_showing_as/?tl=tr
12. Attack Discovery | Elastic Docs, accessed on October 3, 2025,
https://www.elastic.co/docs/solutions/security/ai/attack-discovery

Elastic Security SIEM (On‑Prem) Kurulum Rehberi
Genel Bakış: Orta ölçekli bir kurum için Elastic Security SIEM (Security Information and Event
Management) çözümünün temel (Basic) lisans ile on-premise kurulumu ve log toplama mimarisi bu
rehberde açıklanmaktadır. Amaç, Windows sunucu ve istemcilerden, GNU/Linux sunuculardan, güvenlik
duvarlarından (firewall), SMB dosya sunucularından ve Kaspersky antivirüs sistemlerinden ajan
kullanmadan (mümkün olduğunca agentless) log toplamaktır. Bu yapı tek bir Ubuntu LTS sunucusunda
Elastic Stack 8.x (Elasticsearch + Kibana + opsiyonel Logstash) kurularak ve ayrı bir Windows Event
Forwarding (WEF) sunucusu kullanılarak gerçekleştirilecektir. Toplanan loglar üzerinde temel güvenlik
kuralları tanımlanıp MITRE ATT&CK ve Cyber Kill Chain çerçevelerine uyacak şekilde alarm üretilecek ve
alarm bildirimi e-posta/webhook ile sağlanacaktır.
Mimari ve Gereksinimler
Sunucu Bileşenleri: Elastic Stack tek bir Ubuntu 22.04 LTS sunucusunda çalışacaktır. Bu
sunucuda Elasticsearch (veri depolama ve arama motoru), Kibana (web arayüzü ve SIEM
uygulaması) ve gerekirse Logstash (log toplama ve işleme ardışımı) kurulacaktır. Elastic Stack 8.x
sürümü kullanılacak olup Basic (ücretsiz) lisans ile çalışacaktır. Elastic 8.x sürümü kurulumunda
güvenlik özellikleri (TLS şifreleme, kullanıcı yetkilendirme) varsayılan olarak etkindir ve elastic
süper kullanıcı şifresi kurulum sırasında otomatik oluşturulur .
İstemci/Sistem Kaynakları: Windows istemciler ve sunucular, alan ortamında Windows Event
Forwarding ile loglarını merkezi WEF sunucusuna iletecektir. WEF işlevi için etki alanına dahil bir
Windows Server (örn. Windows Server 2019/2022) kullanılmalıdır. Linux sunucular ve ağ cihazları
(firewall vs.), loglarını Syslog protokolü ile Elastic sunucusuna gönderecektir. Kaspersky antivirüs
yönetim sunucusu (Kaspersky Security Center), SIEM entegrasyon özelliği ile loglarını bir syslog
sunucusuna yönlendirecektir. SMB dosya sunucusu Windows ise WEF kapsamında ele alınacak,
Linux Samba ise syslog üzerinden loglayacaktır.
Donanım Gereksinimleri: Tek sunuculu Elastic Stack kurulumu için en az 4 CPU ve 8-16 GB RAM
önerilir (daha fazla log hacmi için bellek artırılabilir). Elasticsearch, bellek sınırını otomatik ayarlar
ancak genellikle toplam RAM’in %50’si heap olarak kullanılacak şekilde ayarlanmalıdır (ör. 16 GB
RAM için 8 GB heap) . Depolama boyutu, toplanacak logların hacmine göre planlanmalıdır
(örn. birkaç yüz GB). Ubuntu sunucusunda 9200/tcp (Elasticsearch), 5601/tcp (Kibana), 5044/tcp
(Beats/Logstash) ve 514/tcp-udp (Syslog) gibi portların açık olduğundan emin olun. Windows
WEF sunucusu ile Elastic sunucusu arasında 9200/tcp veya 5044/tcp portu üzerinden iletişim
olacaktır.
Ağ ve Güvenlik: Elastic sunucusunu kurarken tüm servisleri yalnızca iç ağdan erişilebilir şekilde
yapılandırın ( network.host: 0.0.0.0 ile dış arayüze açarak, gerekirse firewall ile
kısıtlayarak). Elastic 8.x kurulduğunda transport ve HTTP arayüzü otomatik olarak TLS ile korunur
ve elastic kullanıcısı için şifre üretilir . Bu şifre kurulum çıktısından alınmalı veya daha sonra
değiştirilmeli ve Kibana ile veri toplayıcılar bu kimlik bilgileriyle yapılandırılmalıdır. Basic lisans ile
SIEM dedeksiyon motoru ve ön tanımlı kurallar kullanılabilir durumdadır . Ancak, tespit edilen
alarmların e-posta, webhook gibi harici bildirimleri Basic lisansta kısıtlıdır – harici aksiyon
bağlayıcıları (örn. email, Slack, Jira entegrasyonları) Gold ve üstü lisans gerektirir; Basic sürümde
•
1
•
•
2
•
1
3
1
alarmlar yalnızca Kibana arayüzünde görüntülenebilir veya Elasticsearch indeksine/yığın
günlüğüne yazdırılabilir . Dolayısıyla, üretim ortamında e-posta/webhook ile uyarı iletimi için
Elastic Stack’i deneme süresiyle başlatabilir veya gerekli lisans yükseltmesini planlayabilirsiniz.
Aşağıdaki bölümlerde kurulum ve yapılandırma adımları, log toplama yöntemleri ve SIEM kural
tanımları detaylı şekilde açıklanmaktadır.
Elastic Stack’in Ubuntu Üzerine Kurulumu
1. Elasticsearch Kurulumu ve Yapılandırması
Depo ve Paket Kurulumu: Ubuntu sunucusunda Elastic Stack 8.x paket deposunu ekleyin ve
Elasticsearch’i kurun. GPG imza anahtarını ekleyip depo listesini oluşturduktan sonra paketleri yükleyin:
# Elastic GPG anahtarını ekle
sudo apt update && sudo apt install -y gnupg2 apt-transport-https curl
curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --
dearmor -o /etc/apt/trusted.gpg.d/elastic.gpg
# Elastic 8.x apt deposunu ekle
echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo
tee /etc/apt/sources.list.d/elastic-8.x.list
sudo apt update
sudo apt install -y elasticsearch
Elasticserach 8 kurulumuyla birlikte güvenlik özellikleri otomatik etkinleşir. Kurulum çıktısında elastic
kullanıcısının otomatik oluşturulan şifresi gösterilecektir (bir örnek çıktıda
The generated password for the elastic built-in superuser is : abc123... şeklinde)
. Bu şifreyi bir kenara not edin. Elasticsearch konfigürasyon dosyası /etc/elasticsearch/
elasticsearch.yml altında bulunur. Tek düğümlü bir kurulum yapıldığı için Elastic 8 otomatik olarak
bu düğümü master olarak başlatmak üzere gerekli ayarları (ör. cluster.initial_master_nodes )
ekler. Yine de kontrol ediniz ve cluster isim veya node ismi gibi isteğe bağlı ayarları düzenleyebilirsiniz.
Ayrıca, tüm arayüzlerden erişilebilmesi için network.host değerini 0.0.0.0 yapınız (varsayılan
auto-config ile zaten yapılmış olabilir) . Tek düğümlü cluster olduğu için gerekirse
discovery.type: single-node ayarını da ekleyerek bootstrap kontrol uyarılarını bastırabilirsiniz.
Özetle, bir temel Elasticsearch 8 ayar dosyasındaki kritik kısımlar şöyle görünür:
cluster.name: siem-cluster
node.name: siem-node-1
cluster.initial_master_nodes: ["siem-node-1"]
path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch
network.host: 0.0.0.0
xpack.security.enabled: true
xpack.security.enrollment.enabled: true
4
1
5
2
Not: Elasticsearch 8, kurulumda TLS sertifikalarını otomatik oluşturup ayarlar. Varsayılan
olarak transport ve HTTP arayüzleri için kendi sertifikalarını kullanır ve güvenlik kapalı
bırakılamaz . Bu rehberde tek düğüm olduğu için dahili sertifikalar yeterlidir, ancak
tarayıcıdan Kibana’ya erişimde kendi kendine imzalı sertifika nedeniyle uyarı alırsınız
(devam ederek Kibana’ya erişebilirsiniz veya ileride geçerli bir sertifika yükleyebilirsiniz).
Kurulumdan sonra Elasticsearch servisinin otomatik başlatılması etkinleştirilir ve servis başlatılır:
sudo systemctl daemon-reload
sudo systemctl enable elasticsearch
sudo systemctl start elasticsearch
Elasticsearch başlatıldıktan sonra, sudo systemctl status elasticsearch ile durumunu kontrol
edin. Sunucu çalışmaya başladıktan sonra, curl komutu ile Elasticsearch’e istek atarak yanıt
alabilirsiniz:
curl -k -u elastic:<ELASTIC_ŞİFRENİZ> https://localhost:9200/
Bu komutu elastic kullanıcısının not ettiğiniz şifresiyle deneyerek Elasticsearch’in çalıştığını doğrulayın.
Ayrıca, Linux çekirdek parametresi vm.max_map_count değerinin en az 262144 olduğundan emin
olun (Elasticsearch tavsiyesidir); gerekirse /etc/sysctl.conf dosyasına
vm.max_map_count=262144 ekleyip sudo sysctl -w vm.max_map_count=262144 komutuyla
uygulayın.
2. Kibana Kurulumu ve İlk Ayarlar
Elasticsearch kurulup çalıştıktan sonra Kibana arayüzünü kuralım:
sudo apt install -y kibana
Kibana’nın konfigürasyon dosyası /etc/kibana/kibana.yml yolunda yer alır. Öncelikle Kibana’yı ağ
üzerinden erişilebilir yapmak için server.host: "0.0.0.0" satırını ekleyin veya aktif hale getirin.
Kibana ilk kurulumda Elastic ile güvenli şekilde haberleşmek için kayıt (enrollment) sürecini kullanır. Bu
süreci tamamlamanın iki yolu vardır:
Yöntem A (Enrollment Token ile): Elasticsearch üzerinde Kibana için bir kayıt token’ı oluşturun
ve Kibana’ya bu token’ı verin. Elasticsearch sunucunuzda aşağıdaki komutu çalıştırın:
sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s
kibana
Bu komut bir kayıt token’ı üretecek ve ekrana bastıracaktır. Şimdi Kibana servisini başlatın:
sudo systemctl enable kibana
sudo systemctl start kibana
6 7
•
3
Kibana ilk başlatmada henüz Elasticsearch’e bağlanmadığı için “verification code” adı verilen bir
doğrulama kodu üretir. Bu kodu sudo journalctl -u kibana -f komutuyla Kibana loglarını
izleyerek bulabilirsiniz (6 haneli bir koddur). Ardından, web tarayıcıda https://<SIEMSunucuIP>:
5601 adresine gidin. Kibana web arayüzü ilk açılışta sizden Enrollment Token ve Verification Code
isteyecektir. Elasticsearch’ten aldığınız token’ı ve Kibana logunda gördüğünüz doğrulama kodunu
girerek Kibana’nın Elasticsearch’e bağlanmasını sağlayın. Bu işlem sonucunda Kibana, Elasticsearch
cluster’ına güvenli bir şekilde kayıt olacak ve kibana_system hesabı için gereken ayarlamaları otomatik
yapacaktır. Ardından Kibana sizden elastic süper kullanıcı kimlik bilgilerini isteyerek giriş ekranına
yönlendirecektir. Elastic kurulumundan aldığınız elastic kullanıcı adı ve şifre ile Kibana’ya giriş
yapabilirsiniz.
Yöntem B (Kibana’yı elle yapılandırma): Alternatif olarak, Kibana’yı enrollment süreci olmadan
bağlamak isterseniz Kibana’ya Elasticsearch kullanıcı bilgisini elle verebilirsiniz. Bunun için
(tercihen kibana_system kullanıcısının şifresini bildiğiniz durumda)
elasticsearch.username: "kibana_system" ve elasticsearch.password:
"<kibana_system_şifresi>" ayarlarını kibana.yml dosyasına eklemeniz gerekir. Ancak
kibana_system kullanıcısının varsayılan şifresi belirsizdir; ya üstteki yöntemle kurulum yapılmalı ya
da Elasticsearch’te elasticsearch-reset-password -u kibana_system komutuyla bu
kullanıcının şifresi sıfırlanmalıdır. Daha pratik bir yöntem olarak elastic kullanıcısını da Kibana için
kullanabilirsiniz (küçük test ortamlarında denenebilir): elasticsearch.username:
"elastic" ve elasticsearch.password: "<elastic_şifreniz>" satırlarını Kibana
konfigürasyonuna ekleyip Kibana’yı başlatarak doğrudan elastic hesabıyla bağlanmasını
sağlayabilirsiniz. Not: Bu yöntem güvenlik açısından tavsiye edilmez; üretim öncesi mutlaka
kibana_system hesabı düzeltilmelidir.
Kibana servisini başlatın ve durumunu kontrol edin:
sudo systemctl start kibana
sudo systemctl status kibana
Kibana’nın 5601 portunda dinlediğini ve “Server running” çıktısını loglarda gördükten sonra tarayıcıdan
https://<SIEMSunucuIP>:5601 adresine erişerek Kibana arayüzüne ulaşın. İlk kullanıcı girişi için
elastic hesabını kullanın. Başarılı giriş yaptıktan sonra Kibana’nın Security (SIEM) uygulamasına
menüden erişebilirsiniz. İlerleyen bölümlerde Kibana üzerinden kural ve alarm yönetimine döneceğiz.
3. (Opsiyonel) Logstash Kurulumu
Ajan kullanmadan log toplama hedeflendiği için, merkezi sunucuda Logstash veya Filebeat ile syslog ve
benzeri protokollerle gelen logların toplanması uygun olacaktır. Bu rehberde Logstash kullanılacaktır
(Filebeat ile de benzer sonuç elde edilebilir). Logstash’i apt ile yükleyin:
sudo apt install -y logstash
Logstash, konfigürasyon dosyalarını /etc/logstash/conf.d/ dizininde tutar. Logstash ile Windows
Event Forwarder’dan gelen Beats verisini ve ağ cihazlarından/diğer sunuculardan gelen Syslog verilerini
alacak ve Elasticsearch’e iletecek bir ardışım kurgulayacağız. Aşağıda örnek bir Logstash pipeline
yapılandırması gösterilmiştir:
•
4
# /etc/logstash/conf.d/00-siem-pipeline.conf
input {
beats {
port => 5044
}
udp {
port => 514
type => "syslog"
codec => plain { charset => "UTF-8" }
}
tcp {
port => 514
type => "syslog"
codec => plain { charset => "UTF-8" }
}
}
filter {
if [type] == "syslog" {
# RFC3164 syslog formatına göre mesajı parçala
grok {
match => { "message" => "<%{NUMBER:syslog_pri}>%
{SYSLOGTIMESTAMP:syslog_timestamp} %{HOSTNAME:syslog_hostname} %
{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %
{GREEDYDATA:syslog_message}" }
overwrite => [ "message" ]
}
date {
match => [ "syslog_timestamp", "MMM dd HH:mm:ss", "MMM d HH:mm:ss" ]
timezone => "UTC"
}
# Kaspersky JSON logları için JSON filtre örneği (olası JSON formatı
parse et)
if [syslog_message] =~ "^{\"Event\"" {
json { source => "syslog_message" target => "kaspersky_event" }
}
}
}
output {
elasticsearch {
hosts => ["https://localhost:9200"]
index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
# ya da type alanına göre indeksleme:
# index => "%{[type]}-logs-%{+YYYY.MM.dd}"
user => "elastic"
password => "<elastic_şifreniz>"
ssl => true
cacert => "/etc/elasticsearch/certs/http_ca.crt"
}
}
5
Yukarıdaki yapılandırma şu işleri yapmaktadır:
Input (Girdi): Beats protokolü için 5044/TCP portunda dinler (Winlogbeat bu portu kullanacak).
Ayrıca 514/UDP ve 514/TCP portlarında Syslog mesajlarını dinler. Not: 514 numaralı port
<u>root</u> ayrıcalığı gerektirdiğinden Logstash’in bu portu açabilmesi için servis user’ına
cap_net_bind_service yetkisi verilmeli veya farklı bir port kullanılmalıdır. Güvenlik açısından
dilerseniz 1514 gibi bir port kullanıp firewall cihazlarınızı bu porta yönlendirebilirsiniz. (Örnekte
basitlik için 514 kullanıldı; Ubuntu üzerinde setcap 'cap_net_bind_service=+ep' /usr/
share/logstash/jdk/bin/java komutuyla Java’ya 1024 altı port yetkisi verilebilir veya
iptables ile 514->1514 yönlendirmesi yapılabilir .) Syslog girişlerinde
type => "syslog" etiketi verilerek bu iletilerin filtre aşamasında tanınması sağlanır.
Filter (Filtreleme): type == "syslog" olan (yani syslog protokolünden gelen) iletiler için bir
grok deseni uygulayarak RFC3164 formatındaki log mesajını parçalarız. Örneğin, bir syslog satırı
tipik olarak <PRI>MMM dd HH:mm:ss HOSTNAME PROGRAM[pid]: Message formatındadır
. Yukarıdaki grok ifadesi bu bileşenleri syslog_timestamp , syslog_hostname ,
syslog_program , syslog_pid ve syslog_message alanlarına ayırır. Ardından date
filtresi ile syslog zaman damgasını uygun biçimde @timestamp alanına çeviririz (sistem saat
dilimine göre). Son olarak, eğer syslog mesajı JSON formatlı ise (örneğin Kaspersky olaylarını
JSON yapıda gönderiyorsa) json filtresi ile iç içe parse edilebilir. Kaspersky Security Center
yapılandırmasında, olaylar structured data veya JSON olarak gönderilebilir . JSON tercih
edilirse log içeriği doğrudan alanlara ayrılabileceği için SIEM tarafında daha kullanışlı olacaktır.
Output (Çıktı): Filtrelenip yapılandırılan her bir olay Elasticsearch’e gönderilir. Burada
Elasticsearch output eklentisi kullanılır. Bağlanacağı host https://localhost:9200 olarak
tanımlıdır (Elastic sunucumuz kendisi). Güvenli bağlantı için Elastic’in kurulumda oluşturduğu
sertifikanın CA’si cacert ile belirtilmiştir. Kimlik doğrulama için elastic kullanıcısı (ya da tercih
ederseniz özel bir kullanıcı) bilgisi sağlanmıştır. Index adlandırma şeması olarak örnekte Beat’ten
gelenlere göre indeks kullanılmış ( [@metadata][beat] Winlogbeat’den gelirse “winlogbeat”
olur). Dilerseniz farklı kaynak tiplerine göre indeks ayırabilirsiniz – örneğin tüm syslog tabanlı
loglar için syslog-logs-YYYY.MM.dd gibi bir indeks adı. Bu tercih, arama ve yetkilendirme
planınıza göre şekillenebilir.
Logstash konfigürasyonunu kaydedip Logstash servisinizin otomatik başlamasını sağlayın:
sudo systemctl enable logstash
sudo systemctl start logstash
Artık Elastic sunucunuz, Winlogbeat ajanlarından gelecek verileri 5044 portunda, diğer cihazlardan
gelecek syslog iletilerini 514 portunda dinlemektedir. Not: Syslog protokolü için varsayılan 514/UDP
kullanımı yaygındır ancak UDP iletişiminde paket kaybı riski olduğundan kritik loglar için mümkünse
TCP tercih edilmelidir . Birçok cihaz TCP üzerinden de syslog gönderme desteğine sahiptir ve
güvenlik için 6514/TCP (TLS üzerinden syslog) standardını kullanır . İleride güvenlik duvarı cihazınız
veya diğer sistemleriniz destekliyorsa TLS ile şifreli syslog göndermeyi de düşünebilirsiniz.
Log Toplama Yapılandırması (Agentless)
Kurulum adımlarından sonra, SIEM sunucumuz logları almaya hazırdır. Şimdi Windows, Linux, firewall ve
diğer sistemlerde gerekli yapılandırmaları yaparak logların bu sunucuya aktarılmasını sağlayacağız.
•
8
•
9
10
•
11
12
6
Hedefimiz, mümkün olduğunca ajan kurmadan mevcut sistem özellikleriyle log iletimini
gerçekleştirmektir.
4. Windows Logları – Windows Event Forwarding (WEF)
Mimari: Domain ortamındaki Windows istemci ve sunucular, loglarını bir merkezi Windows Event
Collector sunucusunda toplayacak. Bu merkezi sunucu, “Windows Event Forwarding” (WEF) teknolojisini
kullanarak belirlenen olayları istemcilerden çekebilir. İstemci tarafında herhangi bir ek ajan yüklenmez;
Windows’un yerleşik Event Forwarding mekanizması kullanılır. WEF yapılandırıldıktan sonra, merkezi
sunucudan bu toplanan loglar Elastic Stack’e gönderilecektir. Bu amaçla merkezi sunucuya hafif bir ajan
olan Winlogbeat kurulacaktır (Elastic Agent yerine doğrudan Winlogbeat kullanıyoruz).
WEF Sunucusunu Hazırlama: Etki alanında bir Windows Server (ör. Windows Server 2019) üzerinde
Windows Event Collector servisini yapılandırın. Bu makineyi “kolektör” olarak adlandıracağız. Kolektör
sunucuda yönetici yetkileriyle PowerShell veya Komut İstemi açarak aşağıdaki komutları çalıştırın:
Set-Service -Name WINRM -StartupType Automatic
winrm quickconfig -quiet
wecutil qc /q
Bu komutlar sırasıyla WinRM servisinin otomatik başlamasını sağlar, WinRM’i gelen bağlantıları kabul
edecek şekilde yapılandırır ve Windows Event Collector (WEC) servisinde hızlı konfigürasyon yapar .
Son komut olan wecutil qc , Event Collector’ü etkinleştirir ve gerekli güvenlik gruplarını oluşturur. Bu
noktada kolektör sunucunuz istemcilerden log kabul edebilecek duruma geldi.
Güvenlik İzinleri: WEF mekanizmasında istemci makinelerdeki Network Service hesabı, logları
iletebilmek için okuma iznine ihtiyaç duyar. Bu nedenle bir Grup İlkesi (GPO) ile domain
bilgisayarlarınızda ilgili izinleri tanımlamanız gerekecek. Domain Controller üzerinde Group Policy
Management ile yeni bir GPO oluşturun (örneğin “Event Log Forwarding” adında) ve şu ayarları yapın:
Event Log Readers grubuna Network Service ekleme: Computer Configuration ->
Windows Settings -> Security Settings -> Restricted Groups yoluna giderek
“Event Log Readers” grubuna NT AUTHORITY\NETWORK SERVICE hesabını ekleyin. Bu sayede
Network Service hesabı, yerel olay günlüklerini okuma yetkisine sahip olur.
WinRM istemci ayarı: Computer Configuration -> Administrative Templates ->
Windows Components -> Windows Remote Management -> WinRM Service altında “Allow
Remote Server Management through WinRM” ayarını Etkin yapın ve Filtering kısmına * ile tüm
IP’lerden kabul edecek şekilde düzenleyin veya en azından kolektör sunucusunun IP’sini burada
belirtin.
WEF Abonelik Ayarı: Computer Configuration -> Administrative Templates ->
Windows Components -> Event Forwarding -> Configure target Subscription
Manager ayarını Enabled yapın. Açıklama alanında kolektör sunucuyu gösteren URL’yi girin:
Server=https://<WEFSunucuFQDN>:5986/wsman/SubscriptionManager/
WEC,Refresh=60 . (Burada 5986, WinRM için HTTPS portudur; Refresh=60 saniyede bir
istemcilerin abonelik güncelleme aralığı). Eğer WinRM için HTTP (5985) kullanıyorsanız URL’de
http ve 5985 portu kullanılabilir, ancak güvenlik için domain ortamında Kerberos kullanıldığı
13
•
•
•
7
için şifrelenmemiş de olsa iletişim güvenli olacaktır. Yine de imkan varsa bir internal CA sertifikası
ile WinRM şifrelemesi kurulabilir.
Bu GPO’yu ilgili bilgisayar OU’larına link edin veya Domain Computers grubuna uygulayın. Group Policy
ayarları uygulandıktan sonra (istemcileri yeniden başlatmak ya da gpupdate /force çalıştırmak
gerekebilir), tüm domain bilgisayarları belirlediğiniz kolektör sunucuya log aboneliklerini hazırlayacaktır.
Abonelik Oluşturma: Kolektör (WEC) sunucusunda Event Viewer uygulamasını açın. “Subscriptions”
düğümüne sağ tıklayarak Create Subscription deyin. Bir isim verin (ör. “Forwarded Security Logs”).
Subscription type olarak Collector Initiated seçin (zaten bu yöntem GPO ile bilgisayarlara kolektör
adresini verdik). Source Computers kısmında Domain Computers grubunu veya belirli bilgisayarları
ekleyin (GPO ile izin vermiştik, burada domain genelinde alabiliriz). Events to Collect kısmında hangi
logları istediğinizi tanımlayın: Örneğin Security logundan kritik olaylar (Event ID bazlı filtre
ekleyebilirsiniz) ve System logundan belirli ID’ler vs. Basit bir yaklaşım olarak <All Events> seçilebilir
ancak bu çok veri getireceğinden kritikliğini düşünerek filtreleyin. Tipik olarak orta ölçekli bir SIEM için
aşağıdaki kayıtlar önemlidir:
Security Log: Giriş denemeleri (4624 başarı, 4625 başarısız oturum), kullanıcı/grup değişiklikleri,
önemli policy değişiklikleri, vb. (Microsoft’in “Advanced Audit Policy” ile detaylı alt kategorileri
açılabilir).
System Log: Sistem yeniden başlatma, beklenmedik durma (Event ID 6008), servis hataları vs.
Application Log: Kritik uygulama hataları (tercihe bağlı).
DNS Server, File Server, DHCP gibi spesifik rollere ait loglar o roller için kritikse eklenebilir.
Özel loglar: Örneğin Kaspersky Endpoint Agent’ların olayları Windows Event Log’a yazılıyorsa
(Kaspersky genelde kendi yönetim konsolunda tutar ama yine de uç noktalarda Event Log’a kayıt
bırakabilir), bunlar için de bir Kanal seçilebilir.
Aboneliği oluşturduğunuzda, GPO ayarları da uygulandı ise istemci bilgisayarlar kendi loglarından ilgili
olayları kolektöre göndermeye başlayacak. Kolektör sunucuda bu iletiler Forwarded Events adlı log
altında birikecektir. Önemli: Forwarded Events logunun boyut limitini yükseltmek faydalı olur, çünkü
varsayılan boyut küçük olabilir. Kolektör üzerinde admin komut isteminde şunu çalıştırın:
wevtutil sl "ForwardedEvents" /ms:104857600
Bu komut ForwardedEvents maksimum boyutunu ~100 MB yapar (104857600 bayt) . İhtiyaca göre
daha da artırılabilir (1 GB = 1073741824). Log boyutu dolarsa eski kayıtlar atılacağından, verinin
hacmine uygun bir limit belirleyin.
Winlogbeat ile Elastic’e Aktarım: WEF kolektöründe toplanan logları Elastic’e göndermek için
Winlogbeat kullanacağız. Winlogbeat, Elastic tarafından sağlanan hafif bir Windows hizmetidir ve
Windows Event Log API’lerini kullanarak olayları okuyup gönderebilir. Winlogbeat’i Elastic’in indirme
sayfasından uygun sürüm olarak indirin (Elastic Stack sürümünüzle aynı olmasına dikkat edin, ör. 8.11.x).
Zip dosyasını kolektör sunucuya çıkarın (ör. C:\Program Files\Winlogbeat ).
Winlogbeat’in temel yapılandırma dosyası winlogbeat.yml olarak çıkacaktır. Bu dosyayı düzenleyerek
Forwarded Events logunu izlemesini ve Elastic sunucuya göndermesini sağlamalıyız:
winlogbeat.event_logs listesinde sadece ForwardedEvents kanalını bırakın. Örneğin
varsayılan yml’de Application, Security, System vb. yazar; hepsini kaldırıp sadece:
•
•
•
•
•
14
•
8
winlogbeat.event_logs:
- name: ForwardedEvents
ignore_older: 72h
bırakın . (ignore_older parametresi 72 saatten eski kayıtları görmezden gelir, bu ayarı isteğe göre
değiştirebilirsiniz.)
Elastic’e gönderim ayarları: Winlogbeat doğrudan Elasticsearch’e veya Logstash’e gönderebilir.
Eğer Logstash kullanıyorsanız (yukarıda 5044 portunda Beats input açtık), o zaman
winlogbeat.yml içinde Elasticsearch output’u kapatıp Logstash output’unu açmalısınız. Varsayılan
config’de output.elasticsearch bölümü aktiftir, bunu yorum satırı yapın veya silin .
Sonra output.logstash bölümünü aktif edin ve Logstash sunucusunu girin:
output.logstash:
hosts: ["SIEMSunucuIP:5044"]
Bu şekilde Winlogbeat, logları Logstash’e iletecektir. Logstash de yukarıda kurduğumuz pipeline ile
bunları Elastic’e sokacaktır. Eğer Logstash kullanmıyorsanız, Winlogbeat doğrudan Elasticsearch’e de
gönderebilir; bu durumda output.elasticsearch’u kullanıp Elastic URL’ini (https://SIEMSunucuIP:9200) ve
yetki bilgilerini girmelisiniz (elastic kullanıcı adı/şifresi veya bir API key). Bu rehber Logstash üzerinden
gittiği için output.logstash yöntemi tercih edilmiştir.
(Opsiyonel) TLS Ayarı: Logstash ile iletişimde TLS kullanmak istiyorsanız ve Logstash’i buna göre
ayarladıysanız, Winlogbeat tarafında Logstash’in sertifikasını trust etmek için yml dosyasında
ssl.certificate_authorities parametresine sertifika dosyasının yolunu vermelisiniz.
Örneğin, Elastic Stack kendi sertifikalarıyla çalışıyorsa Logstash’i de aynı CA ile çalıştırıp Windows
tarafına o CA sertifikasını .cer olarak kopyalamanız gerekir. NetSPI’nin ilgili dokümanında
Winlogbeat’e ELK sertifikasının path’ini vererek TLS doğrulaması yaptığını görüyoruz . Test
ortamlarında TLS’yi devre dışı bırakmak için Logstash output’ta ssl.enabled: false de
bırakılabilir.
Yapılandırmayı tamamladıktan sonra PowerShell’i yönetici olarak açın, Winlogbeat klasörüne gidin ( cd
"C:\Program Files\Winlogbeat" ), aşağıdaki komutlarla Winlogbeat’i servis olarak kurup çalıştırın:
.\install-service-winlogbeat.ps1
Set-Service -Name "winlogbeat" -StartupType Automatic
Start-Service "winlogbeat"
Bu noktada WEF kolektör sunucunuz, kendisine iletilen ForwardedEvents logundaki kayıtları Winlogbeat
ile gerçek zamanlı olarak Elastic Stack’e göndermeye başlamış olacaktır. Kibana’da Discover bölümüne
gidip Winlogbeat indeksini (varsayılan indeks adı winlogbeat-8.yyyy-mm-dd şeklinde olacaktır)
kontrol ederek logların gelip gelmediğini doğrulayın. Artık tüm Windows istemci ve sunucu logları
(abonelikte tanımladığınız kapsamda) SIEM’e akmaktadır.
SMB Dosya Sunucusu Logları: İstemcilerin dosya paylaşım erişim kayıtlarını toplamak da isteniyor.
Eğer dosya sunucunuz bir Windows sunucu ise, bunun logları da WEF ile toplanabilir. Dosya
paylaşımlarında detaylı dosya erişim olaylarını alabilmek için Windows’ta ilgili klasörler için Denetim
(Auditing) açmanız gerekir (Nesne Erişimi denetimleri). Örneğin paylaşılan dizinlerde başarılı/başarısız
15
•
16
•
17
9
okuma-yazma olaylarını Security loguna düşürecek şekilde Audit Object Access policy’sini etkinleştirin.
Ardından bu olaylar Security logunda 4663 (nesne erişildi), 4660 (silindi) gibi event’ler olarak
görülecektir. WEF aboneliğinize bu event ID’lerini de dahil ederek dosya sunucusundan bu logların
toplanmasını sağlayabilirsiniz. Eğer SMB sunucusu Linux üzerinde Samba ise, Samba servisinin loglarını
syslog’a yönlendirebilirsiniz (smb.conf içinde logging = syslog ve log level tanımı yaparak). Samba,
dosya erişimlerini detaylı olarak syslog’a yazabilir. Bu iletiler de sonuçta Linux syslog üzerinden SIEM’e
gelecektir (aşağıda Linux syslog kısmına bakınız).
5. Linux Sunucu ve Ağ Cihazı Logları – Syslog ile Toplama
Linux tabanlı sunucular (ör. Ubuntu, CentOS) ve network cihazları (ör. firewall, router, switch) genellikle
Syslog protokolü aracılığıyla merkezi log toplayıcılarına veri gönderebilirler. Amacımız her bir cihaza/
host’a ayrı bir ajan kurmak yerine, halihazırda sistemlerde mevcut olan syslog servislerini kullanarak
logları Elastic’e yönlendirmektir.
Elastic Tarafında Syslog Alıcı: Kurulum aşamasında Logstash’i 514 UDP/TCP portlarında dinleyecek
şekilde yapılandırdık. Eğer Logstash kullanmadan doğrudan Filebeat kullanmayı tercih ederseniz,
Filebeat de benzer şekilde network üzerinden syslog alabilir ancak Elastic 8.14 itibariyle Filebeat’teki
syslog input eklentisi kullanımdan kaldırılıp onun yerine syslog işlemcisi önerilmektedir .
Bu rehber Logstash ile devam etmektedir, ancak ek bir not: Filebeat’in Cisco gibi cihazlara özel modülleri
mevcuttur ve 9001, 9002 gibi portlarda dinleyerek o cihaz loglarını JSON formatına (ECS şemasına)
çevirebilir . İhtiyaç halinde merkezi sunucuya Filebeat de kurulup modüller aktif edilebilir. Örneğin
Cisco ASA firewall logları için Filebeat Cisco modulü syslog üzerinden gelen iletileri parse edebilmektedir
.
Devam edecek olursak, Logstash pipeline’ımız hali hazırda 514 UDP/TCP’den gelen logları syslog
tipiyle yakalayıp grok ile parse edecek şekilde ayarlı. Bu konfigürasyonu cihazlarınızla eşleştirelim:
Firewall Logları: Kurumunuzun güvenlik duvarı cihazını (Fortinet, Palo Alto, SonicWall, Cisco vs. olabilir)
syslog ile SIEM sunucusuna log gönderecek şekilde ayarlayın. Genelde firewall arayüzlerinde Remote
Syslog veya Syslog Server tanımı bulunur. SIEM sunucunuzun IP’sini ve yukarıda belirlediğiniz portu
girerek (UDP 514 veya TCP 5140 gibi) logların gönderimini etkinleştirin. Hangi log seviyelerinin
gönderileceğini seçebilirsiniz (genellikle Informational ve üzeri tüm seviyeler gönderilir). Örneğin bir
Cisco ASA üzerinde logging host <interface> <SIEM_IP> udp/514 komutu ile veya bir
Fortigate üzerinde CLI’da config log syslogd setting altında gerekli ayarlarla bunu
yapabilirsiniz. Önemli: Logstash tarafında parse işlemini özelleştirmeniz gerekebilir. Örneğin Cisco ASA
log formatı standart syslog prefix’inden sonra kendi özgü mesaj formatına sahiptir. Bu durumda
Logstash’te Cisco ASA mesajları için özel grok desenleri kullanmak gerekebilir (Elastic forumlarında veya
Beats modülünde bu hazır bulunur). Temel kurulum aşamasında, tüm syslog mesajları tek bir alanda
kalsa bile en azından SIEM’e gelir; isterseniz daha sonra bu iletiler için geliştirilmiş bir parse pipeline
yazılabilir.
Linux Sunucuların Logları: Linux makinelerde genelde rsyslog veya syslog-ng servisi çalışır. Rsyslog’u
kullanıyorsanız, merkezi sunucuya log forward etmek oldukça kolaydır. İlgili Linux sunucuda /etc/
rsyslog.conf veya /etc/rsyslog.d/ altına bir konfigürasyon ekleyin: Örneğin tüm logları TCP
514 portundan SIEM’e göndermek için:
*.* @@SIEMSunucuIP:514
18 19
20
20
10
satırını ekleyebilirsiniz ( @@ TCP’yi ifade eder, tek @ ise UDP). Bu, o makinedeki tüm logları karşı
sunucuya iletecektir. Daha granuler isterseniz sadece auth.log veya kern.log gibi belirli fasiliteleri de
seçebilirsiniz. Rsyslog config’ini kaydedip servisi restart ettiğinizde, ilgili Linux sunucu artık loglarını
Elastic sunucuya akıtıyor olacaktır. SIEM sunucusunda Logstash bu logları alıp, yukarıdaki grok ile
parçalayacaktır. Linux syslog iletileri zaten RFC3164 formatında olduğu için timestamp, host, süreç adı
gibi bilgiler ayrılacaktır . Sonuçta Elastic’de syslog_hostname alanında logun geldiği makine adı,
syslog_program alanında sürecin adı (sshd, sudo, cron vb.), syslog_message içinde asıl mesaj
görülebilir. Bu alanları kullanarak arama yapabilir veya kural yazabilirsiniz.
Kaspersky Antivirüs Logları: Kurumunuz Kaspersky Endpoint Security kullanıyorsa, bu istemcilerin
ürettiği antivirüs olaylarını merkezi Kaspersky Security Center (KSC) sunucusu toplar. KSC, SIEM
entegrasyonu için yerleşik destek sunar. Kaspersky Security Center’ın yönetim konsolunda ilgili
politikada SIEM Integration ayarlarını bulun. SIEM entegrasyonunu etkinleştirin ve format olarak JSON
veya Structured Data seçeneklerinden birini seçin . JSON formatı Elastic tarafında daha rahat
işlenebilir. Ardından SIEM sunucusunun IP’sini ve portunu girin (yukarıda Logstash için belirlediğimiz
port, örneğin 514 TCP) ve protokolü TCP olarak seçin . KSC, bu ayarlar yapıldıktan sonra
istemcilerden gelen olayları (zararlı yazılım tespit edildi, tarama sonucu, politika ihlalleri vs.) belirttiğiniz
syslog sunucusuna iletmeye başlayacaktır. Kaspersky, ilettiği eventleri seçilebilir kılıyor olabilir: Örneğin
sadece antivirüs olayları, sadece audit olayları gibi filtreler vardır; ihtiyaçlarınıza göre yapılandırın
(varsayılan olarak tüm task ve audit event’leri gönderebilir). Ayrıca KSC, mirror syslog sunucu desteği
de sunar; dilerseniz bir yedek syslog hedefi de belirtebilirsiniz .
Elastic tarafında Kaspersky logları syslog üzerinden geleceği için Logstash bunları da yakalayacaktır.
Eğer JSON formatta geldiyse yukarıda filter içinde eklediğimiz json { source =>
"syslog_message" } bu eventleri parse edip alt alanlara ayıracaktır (örneğin virüs adı, etkilenen
dosya yolu gibi bilgiler JSON içinden çıkarılabilir). Structured data formatı seçildi ise Kaspersky,
mesajlarını key=value çiftleri olarak gönderir; bunları ayrıştırmak için KV filtresi kullanılabilir.
Kaspersky dökümantasyonuna göre, uygulama loglarını SIEM sunucuya iletirken iki format desteklenir
ve amaç SIEM tarafında kolay tanınmasıdır . Bizim tavsiyemiz JSON kullanmanızdır.
Tüm bu ayarlar sonucunda, Windows istemci/sunucu olay kayıtları (WEF+Winlogbeat ile), Linux sistem
günlükleri (rsyslog ile), network cihazlarının logları (syslog ile) ve antivirüs olayları (syslog ile) Elastic
Stack ortamınıza akacaktır. Kibana Discover sekmesinden farklı indekslere göz atarak verinin geldiğini
doğrulayın. Örneğin Winlogbeat verileri winlogbeat-* indeksinde, firewall ve linux log’ları Logstash
çıktı ayarınıza göre syslog-* indeksinde veya Logstash’in varsayılan logstash-* indeksinde
görülebilir. Kaspersky logları da syslog içinde JSON olarak gelecektir.
SIEM Kural Tanımları ve Alarm Üretimi
Topladığımız loglar, Elastic Security uygulaması tarafından analiz edilip alarm üretmek için kullanılabilir.
Elastic Security (SIEM) içinde Detection Engine özelliği mevcuttur ve temel lisansla kullanılabilir
durumdadır. Elastic, pek çok hazır kural setini SIEM ile birlikte sunar – bu kurallar MITRE ATT&CK
framework’ü taktik ve tekniklerine göre etiketlenmiştir ve yaygın saldırı göstergelerini tespit etmeye
yöneliktir . Örneğin brute-force saldırıları, şüpheli süreç çalıştırmaları, yetki yükseltme denemeleri
gibi senaryolar için hazır kurallar bulunmaktadır. Basic lisans ile tüm ön tanımlı (prebuilt) kuralları
yükleyebilir ve kullanabilirsiniz . Kibana arayüzünde Security > Alerts sekmesine ilk girdiğinizde, henüz
kural yüklenmemişse sizden kural setini yüklemenizi isteyebilir (“Load Elastic prebuilt rules”). Bu işlemi
yaparak yüzlerce kuralı sisteme ekleyebilirsiniz. MITRE ATT&CK Coverage sayfasından, kuralların hangi
teknikleri kapsadığını görebilirsiniz – Elastic’in kural seti ilgili MITRE tactic/technique ID’leriyle
eşleştirilmiştir .
9
10 21
22
23 24
10
25
3
26 27
11
Kendi kurumunuza ve log kaynaklarınıza uygun şekilde, gerekli kuralları etkinleştirin veya özelleştirin.
Başlangıç için şu temel güvenlik kullanım senaryolarını ele alabilirsiniz:
Brute Force Giriş Denemeleri: Örneğin Windows domain denetleyicilerinden gelen Event ID
4625 (başarısız giriş) olayları art arda belli eşiğin üzerine çıkarsa alarm üretin. Elastic’in hazır
kural setinde “Multiple Failed Login Attempts” benzeri kurallar mevcuttur. Bu kurallar MITRE
ATT&CK Credential Access (T1110) tekniğine karşılık gelir. Eğer hazır kural yoksa, Threshold rule
türünde bir kural yaratıp belirli bir süre içinde belirli sayıda başarısız oturum açma olayı tespit
edildiğinde tetiklenecek şekilde ayarlayabilirsiniz.
Şüpheli Yönetici Hakları Kullanımı: Örneğin Windows’ta Local Administrator hesabıyla oturum
açılması (4624 logon tipi 10, hedef hesap “Administrator”) veya Linux’ta root ile doğrudan SSH
girişi. Bunlar ender olması gereken olaylar olduğundan, gerçekleştiğinde alarm üretilmesi uygun
olabilir. MITRE ATT&CK’de Privilege Escalation ya da Defense Evasion tekniklerine işaret
edebilir.
Kötü Amaçlı Yazılım Tespiti (AV Logları): Kaspersky logları içinde virüs tespit edildiğine dair bir
event geldiğinde anında Alarm üretmek istersiniz. KSC’den gelen event JSON’unda muhtemelen
ThreatName veya benzeri bir alan olacaktır. Bu alana sahip kayıtlar için özel bir Indicator Match
rule yazabilirsiniz. Örneğin, kaspersky_event.ThreatName:* (herhangi bir değer) koşuluyla
bir kural, her virüs tespitinde alarm üretebilir. Bunu MITRE ATT&CK Execution ya da Impact
fazına bağlayabilirsiniz (örn. Malware etkinliği tespit edildiğinde). Elastic prebuilt kural setinde
bazı antivirüs olayları için kural olmayabilir (Kaspersky entegrasyonu native olmadığı için), bu
durumda custom rule yazmanız gerekecek.
Şüpheli Ağ Erişimleri (Firewall): Firewall loglarınızdaki deny kayıtlarını inceleyerek bir kaynaktan
çok sayıda port taraması veya engellenen bağlantı varsa alarm üretebilirsiniz. Örneğin 1 dakika
içinde 100 farklı porta bağlantı engellendiyse bu bir port scan göstergesidir (MITRE
Reconnaissance/Discovery aşaması). Bu senaryo için bir threshold kuralı oluşturulabilir. Yine
aynı şekilde, firewall’da iç network’ten dışarıya çok sayıda başarısız bağlantı denemesi de
(örneğin malware’in C2 iletişimi kuramaması) alarm değeri taşıyabilir.
Dosya Sunucusunda Toplu Dosya Silme/Erişim: Eğer dosya sunucunuzdan olaylar alıyorsanız
(örneğin Windows’ta 4660 – bir dosya silindi event’i), kısa sürede çok sayıda kritik dosya silinmesi
ransomware habercisi olabilir. Belli bir klasörde belirli sayıda silme olayı threshold’u aşarsa alarm
tetikleyebilirsiniz. Bu, MITRE ATT&CK Impact (T1486 Data Destruction veya T1485 Data
Encryption) aşamasına işaret edebilir. Bu kuralları yazarken SIEM’e gelen Security log verilerini
kullanırsınız.
Elastic Security’nin kural arayüzü oldukça kapsamlıdır. Her kural için bir veya birden fazla koşul, zaman
aralığı, eşik vs. tanımlayabilir ve kuralı belirli aralıklarla çalışacak şekilde zamanlayabilirsiniz. Örneğin
brute-force kuralı her 5 dakikada son 5 dakikayı tarayacak şekilde olabilir.
Kuralları etkinleştirdikten sonra, Alerts sekmesinde tetiklenen alarmları göreceksiniz. Her alarm, ilgili
kural, olay detayları, MITRE tactic/technique bilgileri vb. içerir. Ayrıca timeline ve investigate in timeline
gibi araçlarla analistler bu alarmların detaylarını inceleyebilir.
•
•
•
•
•
12
Alarm Bildirimlerinin Yapılandırılması (E-posta/Webhook)
Kibana, tespit motoru alarmlarını çeşitli aksiyonlarla entegre edebilir (örn. e-posta göndermek, bir HTTP
webhook çağırmak, ServiceNow ticket açmak vb.). Ancak daha önce belirttiğimiz gibi, Basic lisans
seviyesinde bu aksiyonların çoğu etkin değildir. Ücretsiz sürümde yapabileceğiniz aksiyonlar
şunlardır: Elastic indeksine yazma (yani alarmı farklı bir indekse kopyalama) veya Log out (sunucu
loguna yaz) gibi temel aksiyonlar mevcuttur . E-posta, Webhook, Slack gibi harici aksiyonlar lisans
gerektirir (Gold veya Platinum) .
Eğer deneme lisansı aktifleştirirseniz 30 gün boyunca bu özellikleri test edebilirsiniz. Diyelim ki deneme
modundasınız veya lisansınız var, bir e-posta uyarısı kurmak için adımlar:
SMTP Bağlayıcısı Oluşturma: Kibana’da Stack Management > Rules and Connectors >
Connectors bölümüne gidin. “Create connector” deyip Email tipinde bir connector ekleyin. SMTP
sunucu ayarlarınızı girin (örneğin kurum içi bir Exchange varsa veya Gmail SMTP kullanılacaksa
gerekli host, port, TLS vs.). Kimlik doğrulaması gerekiyorsa kullanıcı adı/şifre girin. Connector
oluştururken “Send test email” seçeneğiyle bir deneme gönderebilirsiniz. Bu e-posta
bağlayıcısına bir isim verin (örn. “SOC Alarm Email”).
Webhook Bağlayıcısı (Opsiyonel): Benzer şekilde bir webhook connector tanımlayabilirsiniz.
Örneğin bir Microsoft Teams veya Slack webhook URL’niz varsa, Webhook connector’ü seçip
POST URL’sini girip JSON payload ayarlayabilirsiniz. Basit bir web servis veya chatops
entegrasyonu için webhook kullanımı esnek bir çözümdür.
Kural ile Aksiyonu İlişkilendirme: Mevcut bir alarm kuralını (veya yeni oluştururken)
düzenleyin. Kuralın Actions bölümünde, oluşturduğunuz connector’ü seçin ve eylemi tanımlayın.
Örneğin Email connector seçip “To” adresine SOC ekibinizin e-posta adresini girin, konu satırına
SIEM Alarm - {{rule.name}} gibi bir ifade koyun (değişkenler kullanabilirsiniz), içeriğe de
alarmın özet bilgisini ekleyin. Kibana aksiyon motoru, {{ }} içindeki değişkenleri alarmın
detaylarıyla doldurabilir (örn. {{context.alerts}} ile JSON tüm alarmları geçebilir veya
belirli alanları yazabilir). Basit tutmak gerekirse, “Message” kısmına Kural {{rule.name}}
tetiklendi. {{alerts.total}} olay yakalandı. Kaynak: {{source.ip}}... gibi
ifadeler eklenebilir.
Kural tetiklendiğinde Kibana, tanımlı aksiyonları asenkron olarak çalıştıracaktır. Örneğin bir brute force
alarmı oluştuğunda anında SOC ekibine bir e-posta düşer veya bir webhook ile bir SOAR platformuna
alarm iletilir.
Basic lisans ile harici aksiyonlar mümkün olmadığından, bir alternatif yaklaşım olarak Watchers
kullanılabilirdi ancak Watcher özelliği de eski bir araç olup yerini bu yeni “Rules and Connectors”
altyapısına bırakmıştır ve genelde üst lisans gerektirir. Açık kaynak topluluklarında * ElastAlert* gibi
harici çözümler de bulunuyor ancak Elastic Security artık dahili kural motoruyla bunlara ihtiyacı
azaltmıştır.
Özetle, eğer lisans kısıtı yoksa alarm bildirimi mekanizmanızı mutlaka devreye sokun. Kritik alarmların e-
posta ile 7/24 izlenen bir adrese gitmesi veya yüksek önemde olayların bir ticket açması, olaylara hızlı
yanıt verebilmek için gereklidir. Kibana üzerinde alarm üretildiğini görmek tek başına yeterli olmayabilir,
bu yüzden uygun bir bildirim kanalı entegre edin.
4
4
1.
2.
3.
13
MITRE ATT&CK ve Kill Chain Eşlemesi: Oluşturduğunuz veya etkinleştirdiğiniz her kuralı, kural tanım
ekranında ilgili MITRE ATT&CK tekniği ile etiketlemeyi unutmayın. Elastic’in hazır kurallarında bu zaten
yapılmıştır. Bu sayede SOC ekipleri alarmı gördüğünde hangi aşamaya tekabül ettiğini anlar. Ayrıca
Kibana’daki MITRE ATT&CK coverage ekranından hangi tekniklere karşı ne kadar kapsama sağladığınızı
izleyebilirsiniz. Cyber Kill Chain (Lockheed Martin) fazları da genelde kural açıklamalarında belirtilir (ör.
“Execution” veya “Lateral Movement” aşaması gibi). Bu bağlamda, SIEM’iniz sadece log toplamakla
kalmaz, aynı zamanda bu çerçevelere oturtulmuş bir alarmlama ile proaktif savunma yapmanızı sağlar.
Son olarak, Case Management özelliğini kullanarak oluşan alarmları vakalara dönüştürüp üzerine
notlar alabilir, ilgili ekiplerle paylaşabilirsiniz. Elastic Security, temel düzeyde olay biletleri yönetimine
imkan verir; ancak geniş bir SOC süreci için belki ayrı bir ITSM aracıyla entegrasyon (ServiceNow gibi)
düşünülebilir (bu da yine üst lisans konusudur).
Kurulum ve konfigürasyon bu noktaya kadar tamamlanmıştır. Artık Elastic Security SIEM, belirlediğimiz
kaynaklardan logları toplamakta ve kural motoru ile bunları sürekli tarayarak önemli bir olay
gördüğünde alarm üretmektedir. Sonraki aşamada yapmanız gereken, sistemin bir süre çalışmasına izin
verip normal davranış paternlerini öğrenmek, ardından alarm eşiklerini gerektiği gibi ayarlamak,
gerekirse ek özel kurallar yazarak görünürlüğü artırmaktır.
Aşağıda, yukarıda anlatılan kurulum adımlarını otomatikleştirmek isteyenler için bir kurulum scripti
verilmiştir. Bu Bash script, Ubuntu üzerinde Elasticsearch, Kibana ve Logstash kurulumunu yapıp temel
ayarları uygulamaktadır. Scripti kullanmadan önce içinde tanımlanan parola ve ayarları ortamınıza göre
gözden geçirmeyi unutmayın.
Kurulum Otomasyon Scripti (Bash)
Aşağıdaki bash script, Elastic Stack 8.x’in tek düğüm olarak kurulumu ve temel konfigürasyonlarını
otomatikleştirir. Elasticsearch için elastic süper kullanıcı şifresini rastgele yeniler ve Kibana için bir
enrollment token oluşturur. Logstash’ı ve örnek bir pipeline’ı da ayarlayarak syslog/Beats dinlemeyi
etkinleştirir. Bu scripti root olarak Ubuntu 22.04 LTS sunucunuzda çalıştırabilirsiniz:
#!/bin/bash
# Elastic SIEM On-Prem Kurulum Scripti
### 1. Sistem Hazırlığı
if [ "$(id -u)" != "0" ]; then
echo "Lütfen bu scripti root olarak çalıştırın." >&2
exit 1
fi
echo "[*] APT güncelleniyor ve gerekli paketler kuruluyor..."
apt update && apt install -y apt-transport-https curl gnupg jq
# Elastic APT deposunu ekle
echo "[*] Elastic GPG anahtarı ekleniyor..."
curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | gpg --
dearmor -o /usr/share/keyrings/elastic.gpg
echo "deb [signed-by=/usr/share/keyrings/elastic.gpg] https://
artifacts.elastic.co/packages/8.x/apt stable main" > /etc/apt/sources.list.d/
elastic-8.x.list
14
apt update
### 2. Elasticsearch Kurulumu
echo "[*] Elasticsearch kuruluyor..."
DEBIAN_FRONTEND=noninteractive apt install -y elasticsearch
# Elasticsearch ayarları: network.host herkese açık, single-node mode
echo "[*] Elasticsearch yapılandırılıyor..."
sed -i 's|#network.host: .*|network.host: 0.0.0.0|' /etc/elasticsearch/
elasticsearch.yml
if ! grep -q "^discovery.type" /etc/elasticsearch/elasticsearch.yml; then
echo "discovery.type: single-node" >> /etc/elasticsearch/elasticsearch.yml
fi
# Elasticsearch servisini başlat
systemctl daemon-reload
systemctl enable elasticsearch
systemctl start elasticsearch
# Elastic kullanıcısı şifresini resetle (random) ve al
echo "[*] Elastic kullanıcı şifresi sıfırlanıyor..."
ELASTIC_PW="$(yes | /usr/share/elasticsearch/bin/elasticsearch-reset-
password -u elastic -s -b 2>/dev/null | awk '/New value:/ {print $NF}')"
echo "Yeni 'elastic' şifresi: $ELASTIC_PW"
# Kibana enrollment token al
echo "[*] Kibana için enrollment token alınıyor..."
KIBANA_TOKEN="$(/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-
token -s kibana)"
echo "Kibana Enrollment Token: $KIBANA_TOKEN"
# (Not: Yukarıdaki token, Kibana'yı elle enroll etmek için kullanılacak.
# Script, Kibana enrollment işlemini otomatik yapmamaktadır.)
### 3. Kibana Kurulumu
echo "[*] Kibana kuruluyor..."
apt install -y kibana
# Kibana yapılandır: dış erişim izni
echo "[*] Kibana yapılandırılıyor..."
sed -i 's|#server.host: .*|server.host: "0.0.0.0"|' /etc/kibana/kibana.yml
# (Opsiyonel) Kibana ile Elastic bağlantısı için elastic kullanıcı bilgisi
ayarı:
# sed -i "s|#elasticsearch.username: .*|elasticsearch.username:
\"elastic\"|" /etc/kibana/kibana.yml
# sed -i "s|#elasticsearch.password: .*|elasticsearch.password:
\"$ELASTIC_PW\"|" /etc/kibana/kibana.yml
systemctl enable kibana
15
# Elasticsearch hazır olana kadar bir süre bekle
echo "[*] Kibana başlamadan önce Elasticsearch servisinin tam başlaması için
bekleniyor..."
sleep 20
systemctl start kibana
echo "Kibana başarılı bir şekilde başlatıldı. İlk kurulum için tarayıcıdan
Kibana'ya erişip enrollment token ve verification code adımlarını
tamamlayın."
echo "Elastic 'elastic' kullanıcı yeni şifresi: $ELASTIC_PW"
### 4. Logstash Kurulumu ve Ayarı
echo "[*] Logstash kuruluyor..."
apt install -y logstash
# Basit bir Logstash pipeline oluştur
cat <<'LSCONF' > /etc/logstash/conf.d/00-siem.conf
input {
beats {
port => 5044
}
udp {
port => 514
type => "syslog"
}
tcp {
port => 514
type => "syslog"
}
}
filter {
if [type] == "syslog" {
grok {
match => { "message" => "<%{NUMBER:priority}>%
{SYSLOGTIMESTAMP:syslog_timestamp} %{HOSTNAME:syslog_hostname} %
{DATA:syslog_program}(?:\\[%{POSINT:syslog_pid}\\])?: %
{GREEDYDATA:syslog_message}" }
}
date {
match => [ "syslog_timestamp", "MMM dd HH:mm:ss", "MMM d HH:mm:ss" ]
}
}
}
output {
elasticsearch {
hosts => ["https://localhost:9200"]
index => "syslog-%{+YYYY.MM.dd}"
user => "elastic"
password => "__ELASTIC_PW__"
ssl => true
16
cacert => "/etc/elasticsearch/certs/http_ca.crt"
}
}
LSCONF
# Elastik şifreyi pipeline'a enjekte et
sed -i "s/__ELASTIC_PW__/$ELASTIC_PW/" /etc/logstash/conf.d/00-siem.conf
# Logstash'i başlat
systemctl enable logstash
systemctl start logstash
echo "Kurulum tamamlandı. Elastic Stack (Elasticsearch, Kibana, Logstash)
çalışır durumda."
echo "Kibana erişimi: https://<SunucuIP>:5601 - Elastic kullanıcı adı:
elastic"
echo "NOT: Kibana ilk açılışta Enrollment Token isteyecektir, yukarıda
üretilen tokenı kullanınız."
Script açık bir şekilde adım adım işlemleri yapmaktadır. Kurulum tamamlandıktan sonra, script çıktısında
elastic kullanıcısı için üretilen yeni şifreyi ve Kibana enrollment token’ını göreceksiniz. Bu token’ı
kullanarak Kibana’yı bağlamak yeterlidir (script Kibana’yı otomatik enroll etmiyor; bunu tarayıcıdan ilk
açılışta yapmanız beklenecek). İsterseniz scriptte Kibana’yı elastic kullanıcıyla bağlama satırlarını (yorum
satırı olarak eklenmiştir) açabilirsiniz ancak güvenlik gereksinimleri nedeniyle enrollment yöntemi
önerilir.
Kaynak: Bu script, Elastic Stack 8.x kurulumunu otomatikleştirme konusunda çevrimiçi
topluluklarda paylaşılan örneklerden esinlenmiştir . Elastic 8 ile gelen şifre ve
token oluşturma komutları kullanılarak kesintisiz bir kurulum akışı sağlanmıştır.
Bu rehberde verilen adımları izleyerek, ajan gerektirmeyen ve tek bir sunucuda toplanan loglara dayalı
bir SIEM kurulumu gerçekleştirdik. Orta ölçekli kurumunuz için temel güvenlik izleme ve alarm üretme
yeteneklerini kazanmış oldunuz. Unutmayın ki SIEM çözümleri sürekli iyileştirme gerektirir: Yeni log
kaynakları eklendikçe parse kurallarını güncellemek, yanlış pozitif üreten kuralları ayarlamak, use-
case’lerinizi geliştirmek önemlidir. Elastic Security, esnek ve güçlü bir platform sunar; MITRE ATT&CK
entegrasyonu ve özelleştirilebilir kural yapısıyla kurumunuzun tehdit algılama olgunluğunu artırmanıza
yardımcı olacaktır.
Kaynakça & İleri Okuma:
Elastic ürün dökümantasyonu – [Elastic Stack 8.x Kurulum Kılavuzu (Ubuntu)]
Elastic Security kullanım kılavuzu – SIEM prebuilt kurallar ve MITRE ATT&CK uyumluluğu
Windows Event Forwarding en iyi uygulamaları – Microsoft Docs & Jessica Payne’in MVA videosu
(özet komutlar)
Kaspersky Security Center SIEM entegrasyonu – Kaspersky Support Kılavuzu (Syslog
yapılandırması)
28 29
• 30 1
• 3 26
•
13 15
•
10 22
17
Install ELK Stack 8.x on Ubuntu 24.04/Ubuntu 22.04 - kifarunix.com
https://kifarunix.com/install-elk-stack-8-x-on-ubuntu/
SIEM with Basic License On-Prem? - SIEM - Discuss the Elastic Stack
https://discuss.elastic.co/t/siem-with-basic-license-on-prem/272109
What can I do with Kibana Alerts with BASIC - FREE AND OPEN 2 subscription? - Kibana - Discuss the
Elastic Stack
https://discuss.elastic.co/t/what-can-i-do-with-kibana-alerts-with-basic-free-and-open-2-subscription/278785
Logstash bind to port 514 - Logstash - Discuss the Elastic Stack
https://discuss.elastic.co/t/logstash-bind-to-port-514/44022
A Practical Guide to Logstash: Syslog Deep Dive - Coralogix
https://coralogix.com/blog/a-practical-guide-to-logstash-syslog-deep-dive/
Configuring SIEM integration settings
https://support.kaspersky.com/ksws/11/en-US/146650.htm
Windows Events, Sysmon and Elk…oh my! (Part 2) - NetSPI
https://www.netspi.com/blog/technical-blog/adversary-simulation/windows-events-sysmon-elk-part-2/
Syslog input | Beats
https://www.elastic.co/docs/reference/beats/filebeat/filebeat-input-syslog
Cisco module | Beats - Elastic
https://www.elastic.co/docs/reference/beats/filebeat/filebeat-module-cisco
The full range of Elastic Security's detection engineering capabilities
https://www.elastic.co/blog/elastic-security-detection-engineering
MITRE ATT&CK® coverage | Elastic Docs
https://www.elastic.co/docs/solutions/security/detect-and-alert/mitre-attandckr-coverage
https://svnscha.de/posts/simplify-elasticsearch-kibana/ · GitHub
https://gist.github.com/svnscha/676291c9e1cdbfa261202b3897afba37
1 2 5 6 7 30
3
4
8
9 11 12
10 21 22 23 24
13 14 15 16 17
18 19
20
25
26 27
28 29
18

Elastic Security SIEM (On‑Prem) Kurulum Rehberi
Genel Bakış: Orta ölçekli bir kurum için Elastic Security SIEM (Security Information and Event
Management) çözümünün temel (Basic) lisans ile on-premise kurulumu ve log toplama mimarisi bu
rehberde açıklanmaktadır. Amaç, Windows sunucu ve istemcilerden, GNU/Linux sunuculardan, güvenlik
duvarlarından (firewall), SMB dosya sunucularından ve Kaspersky antivirüs sistemlerinden ajan
kullanmadan (mümkün olduğunca agentless) log toplamaktır. Bu yapı tek bir Ubuntu LTS sunucusunda
Elastic Stack 8.x (Elasticsearch + Kibana + opsiyonel Logstash) kurularak ve ayrı bir Windows Event
Forwarding (WEF) sunucusu kullanılarak gerçekleştirilecektir. Toplanan loglar üzerinde temel güvenlik
kuralları tanımlanıp MITRE ATT&CK ve Cyber Kill Chain çerçevelerine uyacak şekilde alarm üretilecek ve
alarm bildirimi e-posta/webhook ile sağlanacaktır.
Mimari ve Gereksinimler
Sunucu Bileşenleri: Elastic Stack tek bir Ubuntu 22.04 LTS sunucusunda çalışacaktır. Bu
sunucuda Elasticsearch (veri depolama ve arama motoru), Kibana (web arayüzü ve SIEM
uygulaması) ve gerekirse Logstash (log toplama ve işleme ardışımı) kurulacaktır. Elastic Stack 8.x
sürümü kullanılacak olup Basic (ücretsiz) lisans ile çalışacaktır. Elastic 8.x sürümü kurulumunda
güvenlik özellikleri (TLS şifreleme, kullanıcı yetkilendirme) varsayılan olarak etkindir ve elastic
süper kullanıcı şifresi kurulum sırasında otomatik oluşturulur .
İstemci/Sistem Kaynakları: Windows istemciler ve sunucular, alan ortamında Windows Event
Forwarding ile loglarını merkezi WEF sunucusuna iletecektir. WEF işlevi için etki alanına dahil bir
Windows Server (örn. Windows Server 2019/2022) kullanılmalıdır. Linux sunucular ve ağ cihazları
(firewall vs.), loglarını Syslog protokolü ile Elastic sunucusuna gönderecektir. Kaspersky antivirüs
yönetim sunucusu (Kaspersky Security Center), SIEM entegrasyon özelliği ile loglarını bir syslog
sunucusuna yönlendirecektir. SMB dosya sunucusu Windows ise WEF kapsamında ele alınacak,
Linux Samba ise syslog üzerinden loglayacaktır.
Donanım Gereksinimleri: Tek sunuculu Elastic Stack kurulumu için en az 4 CPU ve 8-16 GB RAM
önerilir (daha fazla log hacmi için bellek artırılabilir). Elasticsearch, bellek sınırını otomatik ayarlar
ancak genellikle toplam RAM’in %50’si heap olarak kullanılacak şekilde ayarlanmalıdır (ör. 16 GB
RAM için 8 GB heap) . Depolama boyutu, toplanacak logların hacmine göre planlanmalıdır
(örn. birkaç yüz GB). Ubuntu sunucusunda 9200/tcp (Elasticsearch), 5601/tcp (Kibana), 5044/tcp
(Beats/Logstash) ve 514/tcp-udp (Syslog) gibi portların açık olduğundan emin olun. Windows
WEF sunucusu ile Elastic sunucusu arasında 9200/tcp veya 5044/tcp portu üzerinden iletişim
olacaktır.
Ağ ve Güvenlik: Elastic sunucusunu kurarken tüm servisleri yalnızca iç ağdan erişilebilir şekilde
yapılandırın ( network.host: 0.0.0.0 ile dış arayüze açarak, gerekirse firewall ile
kısıtlayarak). Elastic 8.x kurulduğunda transport ve HTTP arayüzü otomatik olarak TLS ile korunur
ve elastic kullanıcısı için şifre üretilir . Bu şifre kurulum çıktısından alınmalı veya daha sonra
değiştirilmeli ve Kibana ile veri toplayıcılar bu kimlik bilgileriyle yapılandırılmalıdır. Basic lisans ile
SIEM dedeksiyon motoru ve ön tanımlı kurallar kullanılabilir durumdadır . Ancak, tespit edilen
alarmların e-posta, webhook gibi harici bildirimleri Basic lisansta kısıtlıdır – harici aksiyon
bağlayıcıları (örn. email, Slack, Jira entegrasyonları) Gold ve üstü lisans gerektirir; Basic sürümde
•
1
•
•
2
•
1
3
1
alarmlar yalnızca Kibana arayüzünde görüntülenebilir veya Elasticsearch indeksine/yığın
günlüğüne yazdırılabilir . Dolayısıyla, üretim ortamında e-posta/webhook ile uyarı iletimi için
Elastic Stack’i deneme süresiyle başlatabilir veya gerekli lisans yükseltmesini planlayabilirsiniz.
Aşağıdaki bölümlerde kurulum ve yapılandırma adımları, log toplama yöntemleri ve SIEM kural
tanımları detaylı şekilde açıklanmaktadır.
Elastic Stack’in Ubuntu Üzerine Kurulumu
1. Elasticsearch Kurulumu ve Yapılandırması
Depo ve Paket Kurulumu: Ubuntu sunucusunda Elastic Stack 8.x paket deposunu ekleyin ve
Elasticsearch’i kurun. GPG imza anahtarını ekleyip depo listesini oluşturduktan sonra paketleri yükleyin:
# Elastic GPG anahtarını ekle
sudo apt update && sudo apt install -y gnupg2 apt-transport-https curl
curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --
dearmor -o /etc/apt/trusted.gpg.d/elastic.gpg
# Elastic 8.x apt deposunu ekle
echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo
tee /etc/apt/sources.list.d/elastic-8.x.list
sudo apt update
sudo apt install -y elasticsearch
Elasticserach 8 kurulumuyla birlikte güvenlik özellikleri otomatik etkinleşir. Kurulum çıktısında elastic
kullanıcısının otomatik oluşturulan şifresi gösterilecektir (bir örnek çıktıda
The generated password for the elastic built-in superuser is : abc123... şeklinde)
. Bu şifreyi bir kenara not edin. Elasticsearch konfigürasyon dosyası /etc/elasticsearch/
elasticsearch.yml altında bulunur. Tek düğümlü bir kurulum yapıldığı için Elastic 8 otomatik olarak
bu düğümü master olarak başlatmak üzere gerekli ayarları (ör. cluster.initial_master_nodes )
ekler. Yine de kontrol ediniz ve cluster isim veya node ismi gibi isteğe bağlı ayarları düzenleyebilirsiniz.
Ayrıca, tüm arayüzlerden erişilebilmesi için network.host değerini 0.0.0.0 yapınız (varsayılan
auto-config ile zaten yapılmış olabilir) . Tek düğümlü cluster olduğu için gerekirse
discovery.type: single-node ayarını da ekleyerek bootstrap kontrol uyarılarını bastırabilirsiniz.
Özetle, bir temel Elasticsearch 8 ayar dosyasındaki kritik kısımlar şöyle görünür:
cluster.name: siem-cluster
node.name: siem-node-1
cluster.initial_master_nodes: ["siem-node-1"]
path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch
network.host: 0.0.0.0
xpack.security.enabled: true
xpack.security.enrollment.enabled: true
4
1
5
2
Not: Elasticsearch 8, kurulumda TLS sertifikalarını otomatik oluşturup ayarlar. Varsayılan
olarak transport ve HTTP arayüzleri için kendi sertifikalarını kullanır ve güvenlik kapalı
bırakılamaz . Bu rehberde tek düğüm olduğu için dahili sertifikalar yeterlidir, ancak
tarayıcıdan Kibana’ya erişimde kendi kendine imzalı sertifika nedeniyle uyarı alırsınız
(devam ederek Kibana’ya erişebilirsiniz veya ileride geçerli bir sertifika yükleyebilirsiniz).
Kurulumdan sonra Elasticsearch servisinin otomatik başlatılması etkinleştirilir ve servis başlatılır:
sudo systemctl daemon-reload
sudo systemctl enable elasticsearch
sudo systemctl start elasticsearch
Elasticsearch başlatıldıktan sonra, sudo systemctl status elasticsearch ile durumunu kontrol
edin. Sunucu çalışmaya başladıktan sonra, curl komutu ile Elasticsearch’e istek atarak yanıt
alabilirsiniz:
curl -k -u elastic:<ELASTIC_ŞİFRENİZ> https://localhost:9200/
Bu komutu elastic kullanıcısının not ettiğiniz şifresiyle deneyerek Elasticsearch’in çalıştığını doğrulayın.
Ayrıca, Linux çekirdek parametresi vm.max_map_count değerinin en az 262144 olduğundan emin
olun (Elasticsearch tavsiyesidir); gerekirse /etc/sysctl.conf dosyasına
vm.max_map_count=262144 ekleyip sudo sysctl -w vm.max_map_count=262144 komutuyla
uygulayın.
2. Kibana Kurulumu ve İlk Ayarlar
Elasticsearch kurulup çalıştıktan sonra Kibana arayüzünü kuralım:
sudo apt install -y kibana
Kibana’nın konfigürasyon dosyası /etc/kibana/kibana.yml yolunda yer alır. Öncelikle Kibana’yı ağ
üzerinden erişilebilir yapmak için server.host: "0.0.0.0" satırını ekleyin veya aktif hale getirin.
Kibana ilk kurulumda Elastic ile güvenli şekilde haberleşmek için kayıt (enrollment) sürecini kullanır. Bu
süreci tamamlamanın iki yolu vardır:
Yöntem A (Enrollment Token ile): Elasticsearch üzerinde Kibana için bir kayıt token’ı oluşturun
ve Kibana’ya bu token’ı verin. Elasticsearch sunucunuzda aşağıdaki komutu çalıştırın:
sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s
kibana
Bu komut bir kayıt token’ı üretecek ve ekrana bastıracaktır. Şimdi Kibana servisini başlatın:
sudo systemctl enable kibana
sudo systemctl start kibana
6 7
•
3
Kibana ilk başlatmada henüz Elasticsearch’e bağlanmadığı için “verification code” adı verilen bir
doğrulama kodu üretir. Bu kodu sudo journalctl -u kibana -f komutuyla Kibana loglarını
izleyerek bulabilirsiniz (6 haneli bir koddur). Ardından, web tarayıcıda https://<SIEMSunucuIP>:
5601 adresine gidin. Kibana web arayüzü ilk açılışta sizden Enrollment Token ve Verification Code
isteyecektir. Elasticsearch’ten aldığınız token’ı ve Kibana logunda gördüğünüz doğrulama kodunu
girerek Kibana’nın Elasticsearch’e bağlanmasını sağlayın. Bu işlem sonucunda Kibana, Elasticsearch
cluster’ına güvenli bir şekilde kayıt olacak ve kibana_system hesabı için gereken ayarlamaları otomatik
yapacaktır. Ardından Kibana sizden elastic süper kullanıcı kimlik bilgilerini isteyerek giriş ekranına
yönlendirecektir. Elastic kurulumundan aldığınız elastic kullanıcı adı ve şifre ile Kibana’ya giriş
yapabilirsiniz.
Yöntem B (Kibana’yı elle yapılandırma): Alternatif olarak, Kibana’yı enrollment süreci olmadan
bağlamak isterseniz Kibana’ya Elasticsearch kullanıcı bilgisini elle verebilirsiniz. Bunun için
(tercihen kibana_system kullanıcısının şifresini bildiğiniz durumda)
elasticsearch.username: "kibana_system" ve elasticsearch.password:
"<kibana_system_şifresi>" ayarlarını kibana.yml dosyasına eklemeniz gerekir. Ancak
kibana_system kullanıcısının varsayılan şifresi belirsizdir; ya üstteki yöntemle kurulum yapılmalı ya
da Elasticsearch’te elasticsearch-reset-password -u kibana_system komutuyla bu
kullanıcının şifresi sıfırlanmalıdır. Daha pratik bir yöntem olarak elastic kullanıcısını da Kibana için
kullanabilirsiniz (küçük test ortamlarında denenebilir): elasticsearch.username:
"elastic" ve elasticsearch.password: "<elastic_şifreniz>" satırlarını Kibana
konfigürasyonuna ekleyip Kibana’yı başlatarak doğrudan elastic hesabıyla bağlanmasını
sağlayabilirsiniz. Not: Bu yöntem güvenlik açısından tavsiye edilmez; üretim öncesi mutlaka
kibana_system hesabı düzeltilmelidir.
Kibana servisini başlatın ve durumunu kontrol edin:
sudo systemctl start kibana
sudo systemctl status kibana
Kibana’nın 5601 portunda dinlediğini ve “Server running” çıktısını loglarda gördükten sonra tarayıcıdan
https://<SIEMSunucuIP>:5601 adresine erişerek Kibana arayüzüne ulaşın. İlk kullanıcı girişi için
elastic hesabını kullanın. Başarılı giriş yaptıktan sonra Kibana’nın Security (SIEM) uygulamasına
menüden erişebilirsiniz. İlerleyen bölümlerde Kibana üzerinden kural ve alarm yönetimine döneceğiz.
3. (Opsiyonel) Logstash Kurulumu
Ajan kullanmadan log toplama hedeflendiği için, merkezi sunucuda Logstash veya Filebeat ile syslog ve
benzeri protokollerle gelen logların toplanması uygun olacaktır. Bu rehberde Logstash kullanılacaktır
(Filebeat ile de benzer sonuç elde edilebilir). Logstash’i apt ile yükleyin:
sudo apt install -y logstash
Logstash, konfigürasyon dosyalarını /etc/logstash/conf.d/ dizininde tutar. Logstash ile Windows
Event Forwarder’dan gelen Beats verisini ve ağ cihazlarından/diğer sunuculardan gelen Syslog verilerini
alacak ve Elasticsearch’e iletecek bir ardışım kurgulayacağız. Aşağıda örnek bir Logstash pipeline
yapılandırması gösterilmiştir:
•
4
# /etc/logstash/conf.d/00-siem-pipeline.conf
input {
beats {
port => 5044
}
udp {
port => 514
type => "syslog"
codec => plain { charset => "UTF-8" }
}
tcp {
port => 514
type => "syslog"
codec => plain { charset => "UTF-8" }
}
}
filter {
if [type] == "syslog" {
# RFC3164 syslog formatına göre mesajı parçala
grok {
match => { "message" => "<%{NUMBER:syslog_pri}>%
{SYSLOGTIMESTAMP:syslog_timestamp} %{HOSTNAME:syslog_hostname} %
{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %
{GREEDYDATA:syslog_message}" }
overwrite => [ "message" ]
}
date {
match => [ "syslog_timestamp", "MMM dd HH:mm:ss", "MMM d HH:mm:ss" ]
timezone => "UTC"
}
# Kaspersky JSON logları için JSON filtre örneği (olası JSON formatı
parse et)
if [syslog_message] =~ "^{\"Event\"" {
json { source => "syslog_message" target => "kaspersky_event" }
}
}
}
output {
elasticsearch {
hosts => ["https://localhost:9200"]
index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
# ya da type alanına göre indeksleme:
# index => "%{[type]}-logs-%{+YYYY.MM.dd}"
user => "elastic"
password => "<elastic_şifreniz>"
ssl => true
cacert => "/etc/elasticsearch/certs/http_ca.crt"
}
}
5
Yukarıdaki yapılandırma şu işleri yapmaktadır:
Input (Girdi): Beats protokolü için 5044/TCP portunda dinler (Winlogbeat bu portu kullanacak).
Ayrıca 514/UDP ve 514/TCP portlarında Syslog mesajlarını dinler. Not: 514 numaralı port
<u>root</u> ayrıcalığı gerektirdiğinden Logstash’in bu portu açabilmesi için servis user’ına
cap_net_bind_service yetkisi verilmeli veya farklı bir port kullanılmalıdır. Güvenlik açısından
dilerseniz 1514 gibi bir port kullanıp firewall cihazlarınızı bu porta yönlendirebilirsiniz. (Örnekte
basitlik için 514 kullanıldı; Ubuntu üzerinde setcap 'cap_net_bind_service=+ep' /usr/
share/logstash/jdk/bin/java komutuyla Java’ya 1024 altı port yetkisi verilebilir veya
iptables ile 514->1514 yönlendirmesi yapılabilir .) Syslog girişlerinde
type => "syslog" etiketi verilerek bu iletilerin filtre aşamasında tanınması sağlanır.
Filter (Filtreleme): type == "syslog" olan (yani syslog protokolünden gelen) iletiler için bir
grok deseni uygulayarak RFC3164 formatındaki log mesajını parçalarız. Örneğin, bir syslog satırı
tipik olarak <PRI>MMM dd HH:mm:ss HOSTNAME PROGRAM[pid]: Message formatındadır
. Yukarıdaki grok ifadesi bu bileşenleri syslog_timestamp , syslog_hostname ,
syslog_program , syslog_pid ve syslog_message alanlarına ayırır. Ardından date
filtresi ile syslog zaman damgasını uygun biçimde @timestamp alanına çeviririz (sistem saat
dilimine göre). Son olarak, eğer syslog mesajı JSON formatlı ise (örneğin Kaspersky olaylarını
JSON yapıda gönderiyorsa) json filtresi ile iç içe parse edilebilir. Kaspersky Security Center
yapılandırmasında, olaylar structured data veya JSON olarak gönderilebilir . JSON tercih
edilirse log içeriği doğrudan alanlara ayrılabileceği için SIEM tarafında daha kullanışlı olacaktır.
Output (Çıktı): Filtrelenip yapılandırılan her bir olay Elasticsearch’e gönderilir. Burada
Elasticsearch output eklentisi kullanılır. Bağlanacağı host https://localhost:9200 olarak
tanımlıdır (Elastic sunucumuz kendisi). Güvenli bağlantı için Elastic’in kurulumda oluşturduğu
sertifikanın CA’si cacert ile belirtilmiştir. Kimlik doğrulama için elastic kullanıcısı (ya da tercih
ederseniz özel bir kullanıcı) bilgisi sağlanmıştır. Index adlandırma şeması olarak örnekte Beat’ten
gelenlere göre indeks kullanılmış ( [@metadata][beat] Winlogbeat’den gelirse “winlogbeat”
olur). Dilerseniz farklı kaynak tiplerine göre indeks ayırabilirsiniz – örneğin tüm syslog tabanlı
loglar için syslog-logs-YYYY.MM.dd gibi bir indeks adı. Bu tercih, arama ve yetkilendirme
planınıza göre şekillenebilir.
Logstash konfigürasyonunu kaydedip Logstash servisinizin otomatik başlamasını sağlayın:
sudo systemctl enable logstash
sudo systemctl start logstash
Artık Elastic sunucunuz, Winlogbeat ajanlarından gelecek verileri 5044 portunda, diğer cihazlardan
gelecek syslog iletilerini 514 portunda dinlemektedir. Not: Syslog protokolü için varsayılan 514/UDP
kullanımı yaygındır ancak UDP iletişiminde paket kaybı riski olduğundan kritik loglar için mümkünse
TCP tercih edilmelidir . Birçok cihaz TCP üzerinden de syslog gönderme desteğine sahiptir ve
güvenlik için 6514/TCP (TLS üzerinden syslog) standardını kullanır . İleride güvenlik duvarı cihazınız
veya diğer sistemleriniz destekliyorsa TLS ile şifreli syslog göndermeyi de düşünebilirsiniz.
Log Toplama Yapılandırması (Agentless)
Kurulum adımlarından sonra, SIEM sunucumuz logları almaya hazırdır. Şimdi Windows, Linux, firewall ve
diğer sistemlerde gerekli yapılandırmaları yaparak logların bu sunucuya aktarılmasını sağlayacağız.
•
8
•
9
10
•
11
12
6
Hedefimiz, mümkün olduğunca ajan kurmadan mevcut sistem özellikleriyle log iletimini
gerçekleştirmektir.
4. Windows Logları – Windows Event Forwarding (WEF)
Mimari: Domain ortamındaki Windows istemci ve sunucular, loglarını bir merkezi Windows Event
Collector sunucusunda toplayacak. Bu merkezi sunucu, “Windows Event Forwarding” (WEF) teknolojisini
kullanarak belirlenen olayları istemcilerden çekebilir. İstemci tarafında herhangi bir ek ajan yüklenmez;
Windows’un yerleşik Event Forwarding mekanizması kullanılır. WEF yapılandırıldıktan sonra, merkezi
sunucudan bu toplanan loglar Elastic Stack’e gönderilecektir. Bu amaçla merkezi sunucuya hafif bir ajan
olan Winlogbeat kurulacaktır (Elastic Agent yerine doğrudan Winlogbeat kullanıyoruz).
WEF Sunucusunu Hazırlama: Etki alanında bir Windows Server (ör. Windows Server 2019) üzerinde
Windows Event Collector servisini yapılandırın. Bu makineyi “kolektör” olarak adlandıracağız. Kolektör
sunucuda yönetici yetkileriyle PowerShell veya Komut İstemi açarak aşağıdaki komutları çalıştırın:
Set-Service -Name WINRM -StartupType Automatic
winrm quickconfig -quiet
wecutil qc /q
Bu komutlar sırasıyla WinRM servisinin otomatik başlamasını sağlar, WinRM’i gelen bağlantıları kabul
edecek şekilde yapılandırır ve Windows Event Collector (WEC) servisinde hızlı konfigürasyon yapar .
Son komut olan wecutil qc , Event Collector’ü etkinleştirir ve gerekli güvenlik gruplarını oluşturur. Bu
noktada kolektör sunucunuz istemcilerden log kabul edebilecek duruma geldi.
Güvenlik İzinleri: WEF mekanizmasında istemci makinelerdeki Network Service hesabı, logları
iletebilmek için okuma iznine ihtiyaç duyar. Bu nedenle bir Grup İlkesi (GPO) ile domain
bilgisayarlarınızda ilgili izinleri tanımlamanız gerekecek. Domain Controller üzerinde Group Policy
Management ile yeni bir GPO oluşturun (örneğin “Event Log Forwarding” adında) ve şu ayarları yapın:
Event Log Readers grubuna Network Service ekleme: Computer Configuration ->
Windows Settings -> Security Settings -> Restricted Groups yoluna giderek
“Event Log Readers” grubuna NT AUTHORITY\NETWORK SERVICE hesabını ekleyin. Bu sayede
Network Service hesabı, yerel olay günlüklerini okuma yetkisine sahip olur.
WinRM istemci ayarı: Computer Configuration -> Administrative Templates ->
Windows Components -> Windows Remote Management -> WinRM Service altında “Allow
Remote Server Management through WinRM” ayarını Etkin yapın ve Filtering kısmına * ile tüm
IP’lerden kabul edecek şekilde düzenleyin veya en azından kolektör sunucusunun IP’sini burada
belirtin.
WEF Abonelik Ayarı: Computer Configuration -> Administrative Templates ->
Windows Components -> Event Forwarding -> Configure target Subscription
Manager ayarını Enabled yapın. Açıklama alanında kolektör sunucuyu gösteren URL’yi girin:
Server=https://<WEFSunucuFQDN>:5986/wsman/SubscriptionManager/
WEC,Refresh=60 . (Burada 5986, WinRM için HTTPS portudur; Refresh=60 saniyede bir
istemcilerin abonelik güncelleme aralığı). Eğer WinRM için HTTP (5985) kullanıyorsanız URL’de
http ve 5985 portu kullanılabilir, ancak güvenlik için domain ortamında Kerberos kullanıldığı
13
•
•
•
7
için şifrelenmemiş de olsa iletişim güvenli olacaktır. Yine de imkan varsa bir internal CA sertifikası
ile WinRM şifrelemesi kurulabilir.
Bu GPO’yu ilgili bilgisayar OU’larına link edin veya Domain Computers grubuna uygulayın. Group Policy
ayarları uygulandıktan sonra (istemcileri yeniden başlatmak ya da gpupdate /force çalıştırmak
gerekebilir), tüm domain bilgisayarları belirlediğiniz kolektör sunucuya log aboneliklerini hazırlayacaktır.
Abonelik Oluşturma: Kolektör (WEC) sunucusunda Event Viewer uygulamasını açın. “Subscriptions”
düğümüne sağ tıklayarak Create Subscription deyin. Bir isim verin (ör. “Forwarded Security Logs”).
Subscription type olarak Collector Initiated seçin (zaten bu yöntem GPO ile bilgisayarlara kolektör
adresini verdik). Source Computers kısmında Domain Computers grubunu veya belirli bilgisayarları
ekleyin (GPO ile izin vermiştik, burada domain genelinde alabiliriz). Events to Collect kısmında hangi
logları istediğinizi tanımlayın: Örneğin Security logundan kritik olaylar (Event ID bazlı filtre
ekleyebilirsiniz) ve System logundan belirli ID’ler vs. Basit bir yaklaşım olarak <All Events> seçilebilir
ancak bu çok veri getireceğinden kritikliğini düşünerek filtreleyin. Tipik olarak orta ölçekli bir SIEM için
aşağıdaki kayıtlar önemlidir:
Security Log: Giriş denemeleri (4624 başarı, 4625 başarısız oturum), kullanıcı/grup değişiklikleri,
önemli policy değişiklikleri, vb. (Microsoft’in “Advanced Audit Policy” ile detaylı alt kategorileri
açılabilir).
System Log: Sistem yeniden başlatma, beklenmedik durma (Event ID 6008), servis hataları vs.
Application Log: Kritik uygulama hataları (tercihe bağlı).
DNS Server, File Server, DHCP gibi spesifik rollere ait loglar o roller için kritikse eklenebilir.
Özel loglar: Örneğin Kaspersky Endpoint Agent’ların olayları Windows Event Log’a yazılıyorsa
(Kaspersky genelde kendi yönetim konsolunda tutar ama yine de uç noktalarda Event Log’a kayıt
bırakabilir), bunlar için de bir Kanal seçilebilir.
Aboneliği oluşturduğunuzda, GPO ayarları da uygulandı ise istemci bilgisayarlar kendi loglarından ilgili
olayları kolektöre göndermeye başlayacak. Kolektör sunucuda bu iletiler Forwarded Events adlı log
altında birikecektir. Önemli: Forwarded Events logunun boyut limitini yükseltmek faydalı olur, çünkü
varsayılan boyut küçük olabilir. Kolektör üzerinde admin komut isteminde şunu çalıştırın:
wevtutil sl "ForwardedEvents" /ms:104857600
Bu komut ForwardedEvents maksimum boyutunu ~100 MB yapar (104857600 bayt) . İhtiyaca göre
daha da artırılabilir (1 GB = 1073741824). Log boyutu dolarsa eski kayıtlar atılacağından, verinin
hacmine uygun bir limit belirleyin.
Winlogbeat ile Elastic’e Aktarım: WEF kolektöründe toplanan logları Elastic’e göndermek için
Winlogbeat kullanacağız. Winlogbeat, Elastic tarafından sağlanan hafif bir Windows hizmetidir ve
Windows Event Log API’lerini kullanarak olayları okuyup gönderebilir. Winlogbeat’i Elastic’in indirme
sayfasından uygun sürüm olarak indirin (Elastic Stack sürümünüzle aynı olmasına dikkat edin, ör. 8.11.x).
Zip dosyasını kolektör sunucuya çıkarın (ör. C:\Program Files\Winlogbeat ).
Winlogbeat’in temel yapılandırma dosyası winlogbeat.yml olarak çıkacaktır. Bu dosyayı düzenleyerek
Forwarded Events logunu izlemesini ve Elastic sunucuya göndermesini sağlamalıyız:
winlogbeat.event_logs listesinde sadece ForwardedEvents kanalını bırakın. Örneğin
varsayılan yml’de Application, Security, System vb. yazar; hepsini kaldırıp sadece:
•
•
•
•
•
14
•
8
winlogbeat.event_logs:
- name: ForwardedEvents
ignore_older: 72h
bırakın . (ignore_older parametresi 72 saatten eski kayıtları görmezden gelir, bu ayarı isteğe göre
değiştirebilirsiniz.)
Elastic’e gönderim ayarları: Winlogbeat doğrudan Elasticsearch’e veya Logstash’e gönderebilir.
Eğer Logstash kullanıyorsanız (yukarıda 5044 portunda Beats input açtık), o zaman
winlogbeat.yml içinde Elasticsearch output’u kapatıp Logstash output’unu açmalısınız. Varsayılan
config’de output.elasticsearch bölümü aktiftir, bunu yorum satırı yapın veya silin .
Sonra output.logstash bölümünü aktif edin ve Logstash sunucusunu girin:
output.logstash:
hosts: ["SIEMSunucuIP:5044"]
Bu şekilde Winlogbeat, logları Logstash’e iletecektir. Logstash de yukarıda kurduğumuz pipeline ile
bunları Elastic’e sokacaktır. Eğer Logstash kullanmıyorsanız, Winlogbeat doğrudan Elasticsearch’e de
gönderebilir; bu durumda output.elasticsearch’u kullanıp Elastic URL’ini (https://SIEMSunucuIP:9200) ve
yetki bilgilerini girmelisiniz (elastic kullanıcı adı/şifresi veya bir API key). Bu rehber Logstash üzerinden
gittiği için output.logstash yöntemi tercih edilmiştir.
(Opsiyonel) TLS Ayarı: Logstash ile iletişimde TLS kullanmak istiyorsanız ve Logstash’i buna göre
ayarladıysanız, Winlogbeat tarafında Logstash’in sertifikasını trust etmek için yml dosyasında
ssl.certificate_authorities parametresine sertifika dosyasının yolunu vermelisiniz.
Örneğin, Elastic Stack kendi sertifikalarıyla çalışıyorsa Logstash’i de aynı CA ile çalıştırıp Windows
tarafına o CA sertifikasını .cer olarak kopyalamanız gerekir. NetSPI’nin ilgili dokümanında
Winlogbeat’e ELK sertifikasının path’ini vererek TLS doğrulaması yaptığını görüyoruz . Test
ortamlarında TLS’yi devre dışı bırakmak için Logstash output’ta ssl.enabled: false de
bırakılabilir.
Yapılandırmayı tamamladıktan sonra PowerShell’i yönetici olarak açın, Winlogbeat klasörüne gidin ( cd
"C:\Program Files\Winlogbeat" ), aşağıdaki komutlarla Winlogbeat’i servis olarak kurup çalıştırın:
.\install-service-winlogbeat.ps1
Set-Service -Name "winlogbeat" -StartupType Automatic
Start-Service "winlogbeat"
Bu noktada WEF kolektör sunucunuz, kendisine iletilen ForwardedEvents logundaki kayıtları Winlogbeat
ile gerçek zamanlı olarak Elastic Stack’e göndermeye başlamış olacaktır. Kibana’da Discover bölümüne
gidip Winlogbeat indeksini (varsayılan indeks adı winlogbeat-8.yyyy-mm-dd şeklinde olacaktır)
kontrol ederek logların gelip gelmediğini doğrulayın. Artık tüm Windows istemci ve sunucu logları
(abonelikte tanımladığınız kapsamda) SIEM’e akmaktadır.
SMB Dosya Sunucusu Logları: İstemcilerin dosya paylaşım erişim kayıtlarını toplamak da isteniyor.
Eğer dosya sunucunuz bir Windows sunucu ise, bunun logları da WEF ile toplanabilir. Dosya
paylaşımlarında detaylı dosya erişim olaylarını alabilmek için Windows’ta ilgili klasörler için Denetim
(Auditing) açmanız gerekir (Nesne Erişimi denetimleri). Örneğin paylaşılan dizinlerde başarılı/başarısız
15
•
16
•
17
9
okuma-yazma olaylarını Security loguna düşürecek şekilde Audit Object Access policy’sini etkinleştirin.
Ardından bu olaylar Security logunda 4663 (nesne erişildi), 4660 (silindi) gibi event’ler olarak
görülecektir. WEF aboneliğinize bu event ID’lerini de dahil ederek dosya sunucusundan bu logların
toplanmasını sağlayabilirsiniz. Eğer SMB sunucusu Linux üzerinde Samba ise, Samba servisinin loglarını
syslog’a yönlendirebilirsiniz (smb.conf içinde logging = syslog ve log level tanımı yaparak). Samba,
dosya erişimlerini detaylı olarak syslog’a yazabilir. Bu iletiler de sonuçta Linux syslog üzerinden SIEM’e
gelecektir (aşağıda Linux syslog kısmına bakınız).
5. Linux Sunucu ve Ağ Cihazı Logları – Syslog ile Toplama
Linux tabanlı sunucular (ör. Ubuntu, CentOS) ve network cihazları (ör. firewall, router, switch) genellikle
Syslog protokolü aracılığıyla merkezi log toplayıcılarına veri gönderebilirler. Amacımız her bir cihaza/
host’a ayrı bir ajan kurmak yerine, halihazırda sistemlerde mevcut olan syslog servislerini kullanarak
logları Elastic’e yönlendirmektir.
Elastic Tarafında Syslog Alıcı: Kurulum aşamasında Logstash’i 514 UDP/TCP portlarında dinleyecek
şekilde yapılandırdık. Eğer Logstash kullanmadan doğrudan Filebeat kullanmayı tercih ederseniz,
Filebeat de benzer şekilde network üzerinden syslog alabilir ancak Elastic 8.14 itibariyle Filebeat’teki
syslog input eklentisi kullanımdan kaldırılıp onun yerine syslog işlemcisi önerilmektedir .
Bu rehber Logstash ile devam etmektedir, ancak ek bir not: Filebeat’in Cisco gibi cihazlara özel modülleri
mevcuttur ve 9001, 9002 gibi portlarda dinleyerek o cihaz loglarını JSON formatına (ECS şemasına)
çevirebilir . İhtiyaç halinde merkezi sunucuya Filebeat de kurulup modüller aktif edilebilir. Örneğin
Cisco ASA firewall logları için Filebeat Cisco modulü syslog üzerinden gelen iletileri parse edebilmektedir
.
Devam edecek olursak, Logstash pipeline’ımız hali hazırda 514 UDP/TCP’den gelen logları syslog
tipiyle yakalayıp grok ile parse edecek şekilde ayarlı. Bu konfigürasyonu cihazlarınızla eşleştirelim:
Firewall Logları: Kurumunuzun güvenlik duvarı cihazını (Fortinet, Palo Alto, SonicWall, Cisco vs. olabilir)
syslog ile SIEM sunucusuna log gönderecek şekilde ayarlayın. Genelde firewall arayüzlerinde Remote
Syslog veya Syslog Server tanımı bulunur. SIEM sunucunuzun IP’sini ve yukarıda belirlediğiniz portu
girerek (UDP 514 veya TCP 5140 gibi) logların gönderimini etkinleştirin. Hangi log seviyelerinin
gönderileceğini seçebilirsiniz (genellikle Informational ve üzeri tüm seviyeler gönderilir). Örneğin bir
Cisco ASA üzerinde logging host <interface> <SIEM_IP> udp/514 komutu ile veya bir
Fortigate üzerinde CLI’da config log syslogd setting altında gerekli ayarlarla bunu
yapabilirsiniz. Önemli: Logstash tarafında parse işlemini özelleştirmeniz gerekebilir. Örneğin Cisco ASA
log formatı standart syslog prefix’inden sonra kendi özgü mesaj formatına sahiptir. Bu durumda
Logstash’te Cisco ASA mesajları için özel grok desenleri kullanmak gerekebilir (Elastic forumlarında veya
Beats modülünde bu hazır bulunur). Temel kurulum aşamasında, tüm syslog mesajları tek bir alanda
kalsa bile en azından SIEM’e gelir; isterseniz daha sonra bu iletiler için geliştirilmiş bir parse pipeline
yazılabilir.
Linux Sunucuların Logları: Linux makinelerde genelde rsyslog veya syslog-ng servisi çalışır. Rsyslog’u
kullanıyorsanız, merkezi sunucuya log forward etmek oldukça kolaydır. İlgili Linux sunucuda /etc/
rsyslog.conf veya /etc/rsyslog.d/ altına bir konfigürasyon ekleyin: Örneğin tüm logları TCP
514 portundan SIEM’e göndermek için:
*.* @@SIEMSunucuIP:514
18 19
20
20
10
satırını ekleyebilirsiniz ( @@ TCP’yi ifade eder, tek @ ise UDP). Bu, o makinedeki tüm logları karşı
sunucuya iletecektir. Daha granuler isterseniz sadece auth.log veya kern.log gibi belirli fasiliteleri de
seçebilirsiniz. Rsyslog config’ini kaydedip servisi restart ettiğinizde, ilgili Linux sunucu artık loglarını
Elastic sunucuya akıtıyor olacaktır. SIEM sunucusunda Logstash bu logları alıp, yukarıdaki grok ile
parçalayacaktır. Linux syslog iletileri zaten RFC3164 formatında olduğu için timestamp, host, süreç adı
gibi bilgiler ayrılacaktır . Sonuçta Elastic’de syslog_hostname alanında logun geldiği makine adı,
syslog_program alanında sürecin adı (sshd, sudo, cron vb.), syslog_message içinde asıl mesaj
görülebilir. Bu alanları kullanarak arama yapabilir veya kural yazabilirsiniz.
Kaspersky Antivirüs Logları: Kurumunuz Kaspersky Endpoint Security kullanıyorsa, bu istemcilerin
ürettiği antivirüs olaylarını merkezi Kaspersky Security Center (KSC) sunucusu toplar. KSC, SIEM
entegrasyonu için yerleşik destek sunar. Kaspersky Security Center’ın yönetim konsolunda ilgili
politikada SIEM Integration ayarlarını bulun. SIEM entegrasyonunu etkinleştirin ve format olarak JSON
veya Structured Data seçeneklerinden birini seçin . JSON formatı Elastic tarafında daha rahat
işlenebilir. Ardından SIEM sunucusunun IP’sini ve portunu girin (yukarıda Logstash için belirlediğimiz
port, örneğin 514 TCP) ve protokolü TCP olarak seçin . KSC, bu ayarlar yapıldıktan sonra
istemcilerden gelen olayları (zararlı yazılım tespit edildi, tarama sonucu, politika ihlalleri vs.) belirttiğiniz
syslog sunucusuna iletmeye başlayacaktır. Kaspersky, ilettiği eventleri seçilebilir kılıyor olabilir: Örneğin
sadece antivirüs olayları, sadece audit olayları gibi filtreler vardır; ihtiyaçlarınıza göre yapılandırın
(varsayılan olarak tüm task ve audit event’leri gönderebilir). Ayrıca KSC, mirror syslog sunucu desteği
de sunar; dilerseniz bir yedek syslog hedefi de belirtebilirsiniz .
Elastic tarafında Kaspersky logları syslog üzerinden geleceği için Logstash bunları da yakalayacaktır.
Eğer JSON formatta geldiyse yukarıda filter içinde eklediğimiz json { source =>
"syslog_message" } bu eventleri parse edip alt alanlara ayıracaktır (örneğin virüs adı, etkilenen
dosya yolu gibi bilgiler JSON içinden çıkarılabilir). Structured data formatı seçildi ise Kaspersky,
mesajlarını key=value çiftleri olarak gönderir; bunları ayrıştırmak için KV filtresi kullanılabilir.
Kaspersky dökümantasyonuna göre, uygulama loglarını SIEM sunucuya iletirken iki format desteklenir
ve amaç SIEM tarafında kolay tanınmasıdır . Bizim tavsiyemiz JSON kullanmanızdır.
Tüm bu ayarlar sonucunda, Windows istemci/sunucu olay kayıtları (WEF+Winlogbeat ile), Linux sistem
günlükleri (rsyslog ile), network cihazlarının logları (syslog ile) ve antivirüs olayları (syslog ile) Elastic
Stack ortamınıza akacaktır. Kibana Discover sekmesinden farklı indekslere göz atarak verinin geldiğini
doğrulayın. Örneğin Winlogbeat verileri winlogbeat-* indeksinde, firewall ve linux log’ları Logstash
çıktı ayarınıza göre syslog-* indeksinde veya Logstash’in varsayılan logstash-* indeksinde
görülebilir. Kaspersky logları da syslog içinde JSON olarak gelecektir.
SIEM Kural Tanımları ve Alarm Üretimi
Topladığımız loglar, Elastic Security uygulaması tarafından analiz edilip alarm üretmek için kullanılabilir.
Elastic Security (SIEM) içinde Detection Engine özelliği mevcuttur ve temel lisansla kullanılabilir
durumdadır. Elastic, pek çok hazır kural setini SIEM ile birlikte sunar – bu kurallar MITRE ATT&CK
framework’ü taktik ve tekniklerine göre etiketlenmiştir ve yaygın saldırı göstergelerini tespit etmeye
yöneliktir . Örneğin brute-force saldırıları, şüpheli süreç çalıştırmaları, yetki yükseltme denemeleri
gibi senaryolar için hazır kurallar bulunmaktadır. Basic lisans ile tüm ön tanımlı (prebuilt) kuralları
yükleyebilir ve kullanabilirsiniz . Kibana arayüzünde Security > Alerts sekmesine ilk girdiğinizde, henüz
kural yüklenmemişse sizden kural setini yüklemenizi isteyebilir (“Load Elastic prebuilt rules”). Bu işlemi
yaparak yüzlerce kuralı sisteme ekleyebilirsiniz. MITRE ATT&CK Coverage sayfasından, kuralların hangi
teknikleri kapsadığını görebilirsiniz – Elastic’in kural seti ilgili MITRE tactic/technique ID’leriyle
eşleştirilmiştir .
9
10 21
22
23 24
10
25
3
26 27
11
Kendi kurumunuza ve log kaynaklarınıza uygun şekilde, gerekli kuralları etkinleştirin veya özelleştirin.
Başlangıç için şu temel güvenlik kullanım senaryolarını ele alabilirsiniz:
Brute Force Giriş Denemeleri: Örneğin Windows domain denetleyicilerinden gelen Event ID
4625 (başarısız giriş) olayları art arda belli eşiğin üzerine çıkarsa alarm üretin. Elastic’in hazır
kural setinde “Multiple Failed Login Attempts” benzeri kurallar mevcuttur. Bu kurallar MITRE
ATT&CK Credential Access (T1110) tekniğine karşılık gelir. Eğer hazır kural yoksa, Threshold rule
türünde bir kural yaratıp belirli bir süre içinde belirli sayıda başarısız oturum açma olayı tespit
edildiğinde tetiklenecek şekilde ayarlayabilirsiniz.
Şüpheli Yönetici Hakları Kullanımı: Örneğin Windows’ta Local Administrator hesabıyla oturum
açılması (4624 logon tipi 10, hedef hesap “Administrator”) veya Linux’ta root ile doğrudan SSH
girişi. Bunlar ender olması gereken olaylar olduğundan, gerçekleştiğinde alarm üretilmesi uygun
olabilir. MITRE ATT&CK’de Privilege Escalation ya da Defense Evasion tekniklerine işaret
edebilir.
Kötü Amaçlı Yazılım Tespiti (AV Logları): Kaspersky logları içinde virüs tespit edildiğine dair bir
event geldiğinde anında Alarm üretmek istersiniz. KSC’den gelen event JSON’unda muhtemelen
ThreatName veya benzeri bir alan olacaktır. Bu alana sahip kayıtlar için özel bir Indicator Match
rule yazabilirsiniz. Örneğin, kaspersky_event.ThreatName:* (herhangi bir değer) koşuluyla
bir kural, her virüs tespitinde alarm üretebilir. Bunu MITRE ATT&CK Execution ya da Impact
fazına bağlayabilirsiniz (örn. Malware etkinliği tespit edildiğinde). Elastic prebuilt kural setinde
bazı antivirüs olayları için kural olmayabilir (Kaspersky entegrasyonu native olmadığı için), bu
durumda custom rule yazmanız gerekecek.
Şüpheli Ağ Erişimleri (Firewall): Firewall loglarınızdaki deny kayıtlarını inceleyerek bir kaynaktan
çok sayıda port taraması veya engellenen bağlantı varsa alarm üretebilirsiniz. Örneğin 1 dakika
içinde 100 farklı porta bağlantı engellendiyse bu bir port scan göstergesidir (MITRE
Reconnaissance/Discovery aşaması). Bu senaryo için bir threshold kuralı oluşturulabilir. Yine
aynı şekilde, firewall’da iç network’ten dışarıya çok sayıda başarısız bağlantı denemesi de
(örneğin malware’in C2 iletişimi kuramaması) alarm değeri taşıyabilir.
Dosya Sunucusunda Toplu Dosya Silme/Erişim: Eğer dosya sunucunuzdan olaylar alıyorsanız
(örneğin Windows’ta 4660 – bir dosya silindi event’i), kısa sürede çok sayıda kritik dosya silinmesi
ransomware habercisi olabilir. Belli bir klasörde belirli sayıda silme olayı threshold’u aşarsa alarm
tetikleyebilirsiniz. Bu, MITRE ATT&CK Impact (T1486 Data Destruction veya T1485 Data
Encryption) aşamasına işaret edebilir. Bu kuralları yazarken SIEM’e gelen Security log verilerini
kullanırsınız.
Elastic Security’nin kural arayüzü oldukça kapsamlıdır. Her kural için bir veya birden fazla koşul, zaman
aralığı, eşik vs. tanımlayabilir ve kuralı belirli aralıklarla çalışacak şekilde zamanlayabilirsiniz. Örneğin
brute-force kuralı her 5 dakikada son 5 dakikayı tarayacak şekilde olabilir.
Kuralları etkinleştirdikten sonra, Alerts sekmesinde tetiklenen alarmları göreceksiniz. Her alarm, ilgili
kural, olay detayları, MITRE tactic/technique bilgileri vb. içerir. Ayrıca timeline ve investigate in timeline
gibi araçlarla analistler bu alarmların detaylarını inceleyebilir.
•
•
•
•
•
12
Alarm Bildirimlerinin Yapılandırılması (E-posta/Webhook)
Kibana, tespit motoru alarmlarını çeşitli aksiyonlarla entegre edebilir (örn. e-posta göndermek, bir HTTP
webhook çağırmak, ServiceNow ticket açmak vb.). Ancak daha önce belirttiğimiz gibi, Basic lisans
seviyesinde bu aksiyonların çoğu etkin değildir. Ücretsiz sürümde yapabileceğiniz aksiyonlar
şunlardır: Elastic indeksine yazma (yani alarmı farklı bir indekse kopyalama) veya Log out (sunucu
loguna yaz) gibi temel aksiyonlar mevcuttur . E-posta, Webhook, Slack gibi harici aksiyonlar lisans
gerektirir (Gold veya Platinum) .
Eğer deneme lisansı aktifleştirirseniz 30 gün boyunca bu özellikleri test edebilirsiniz. Diyelim ki deneme
modundasınız veya lisansınız var, bir e-posta uyarısı kurmak için adımlar:
SMTP Bağlayıcısı Oluşturma: Kibana’da Stack Management > Rules and Connectors >
Connectors bölümüne gidin. “Create connector” deyip Email tipinde bir connector ekleyin. SMTP
sunucu ayarlarınızı girin (örneğin kurum içi bir Exchange varsa veya Gmail SMTP kullanılacaksa
gerekli host, port, TLS vs.). Kimlik doğrulaması gerekiyorsa kullanıcı adı/şifre girin. Connector
oluştururken “Send test email” seçeneğiyle bir deneme gönderebilirsiniz. Bu e-posta
bağlayıcısına bir isim verin (örn. “SOC Alarm Email”).
Webhook Bağlayıcısı (Opsiyonel): Benzer şekilde bir webhook connector tanımlayabilirsiniz.
Örneğin bir Microsoft Teams veya Slack webhook URL’niz varsa, Webhook connector’ü seçip
POST URL’sini girip JSON payload ayarlayabilirsiniz. Basit bir web servis veya chatops
entegrasyonu için webhook kullanımı esnek bir çözümdür.
Kural ile Aksiyonu İlişkilendirme: Mevcut bir alarm kuralını (veya yeni oluştururken)
düzenleyin. Kuralın Actions bölümünde, oluşturduğunuz connector’ü seçin ve eylemi tanımlayın.
Örneğin Email connector seçip “To” adresine SOC ekibinizin e-posta adresini girin, konu satırına
SIEM Alarm - {{rule.name}} gibi bir ifade koyun (değişkenler kullanabilirsiniz), içeriğe de
alarmın özet bilgisini ekleyin. Kibana aksiyon motoru, {{ }} içindeki değişkenleri alarmın
detaylarıyla doldurabilir (örn. {{context.alerts}} ile JSON tüm alarmları geçebilir veya
belirli alanları yazabilir). Basit tutmak gerekirse, “Message” kısmına Kural {{rule.name}}
tetiklendi. {{alerts.total}} olay yakalandı. Kaynak: {{source.ip}}... gibi
ifadeler eklenebilir.
Kural tetiklendiğinde Kibana, tanımlı aksiyonları asenkron olarak çalıştıracaktır. Örneğin bir brute force
alarmı oluştuğunda anında SOC ekibine bir e-posta düşer veya bir webhook ile bir SOAR platformuna
alarm iletilir.
Basic lisans ile harici aksiyonlar mümkün olmadığından, bir alternatif yaklaşım olarak Watchers
kullanılabilirdi ancak Watcher özelliği de eski bir araç olup yerini bu yeni “Rules and Connectors”
altyapısına bırakmıştır ve genelde üst lisans gerektirir. Açık kaynak topluluklarında * ElastAlert* gibi
harici çözümler de bulunuyor ancak Elastic Security artık dahili kural motoruyla bunlara ihtiyacı
azaltmıştır.
Özetle, eğer lisans kısıtı yoksa alarm bildirimi mekanizmanızı mutlaka devreye sokun. Kritik alarmların e-
posta ile 7/24 izlenen bir adrese gitmesi veya yüksek önemde olayların bir ticket açması, olaylara hızlı
yanıt verebilmek için gereklidir. Kibana üzerinde alarm üretildiğini görmek tek başına yeterli olmayabilir,
bu yüzden uygun bir bildirim kanalı entegre edin.
4
4
1.
2.
3.
13
MITRE ATT&CK ve Kill Chain Eşlemesi: Oluşturduğunuz veya etkinleştirdiğiniz her kuralı, kural tanım
ekranında ilgili MITRE ATT&CK tekniği ile etiketlemeyi unutmayın. Elastic’in hazır kurallarında bu zaten
yapılmıştır. Bu sayede SOC ekipleri alarmı gördüğünde hangi aşamaya tekabül ettiğini anlar. Ayrıca
Kibana’daki MITRE ATT&CK coverage ekranından hangi tekniklere karşı ne kadar kapsama sağladığınızı
izleyebilirsiniz. Cyber Kill Chain (Lockheed Martin) fazları da genelde kural açıklamalarında belirtilir (ör.
“Execution” veya “Lateral Movement” aşaması gibi). Bu bağlamda, SIEM’iniz sadece log toplamakla
kalmaz, aynı zamanda bu çerçevelere oturtulmuş bir alarmlama ile proaktif savunma yapmanızı sağlar.
Son olarak, Case Management özelliğini kullanarak oluşan alarmları vakalara dönüştürüp üzerine
notlar alabilir, ilgili ekiplerle paylaşabilirsiniz. Elastic Security, temel düzeyde olay biletleri yönetimine
imkan verir; ancak geniş bir SOC süreci için belki ayrı bir ITSM aracıyla entegrasyon (ServiceNow gibi)
düşünülebilir (bu da yine üst lisans konusudur).
Kurulum ve konfigürasyon bu noktaya kadar tamamlanmıştır. Artık Elastic Security SIEM, belirlediğimiz
kaynaklardan logları toplamakta ve kural motoru ile bunları sürekli tarayarak önemli bir olay
gördüğünde alarm üretmektedir. Sonraki aşamada yapmanız gereken, sistemin bir süre çalışmasına izin
verip normal davranış paternlerini öğrenmek, ardından alarm eşiklerini gerektiği gibi ayarlamak,
gerekirse ek özel kurallar yazarak görünürlüğü artırmaktır.
Aşağıda, yukarıda anlatılan kurulum adımlarını otomatikleştirmek isteyenler için bir kurulum scripti
verilmiştir. Bu Bash script, Ubuntu üzerinde Elasticsearch, Kibana ve Logstash kurulumunu yapıp temel
ayarları uygulamaktadır. Scripti kullanmadan önce içinde tanımlanan parola ve ayarları ortamınıza göre
gözden geçirmeyi unutmayın.
Kurulum Otomasyon Scripti (Bash)
Aşağıdaki bash script, Elastic Stack 8.x’in tek düğüm olarak kurulumu ve temel konfigürasyonlarını
otomatikleştirir. Elasticsearch için elastic süper kullanıcı şifresini rastgele yeniler ve Kibana için bir
enrollment token oluşturur. Logstash’ı ve örnek bir pipeline’ı da ayarlayarak syslog/Beats dinlemeyi
etkinleştirir. Bu scripti root olarak Ubuntu 22.04 LTS sunucunuzda çalıştırabilirsiniz:
#!/bin/bash
# Elastic SIEM On-Prem Kurulum Scripti
### 1. Sistem Hazırlığı
if [ "$(id -u)" != "0" ]; then
echo "Lütfen bu scripti root olarak çalıştırın." >&2
exit 1
fi
echo "[*] APT güncelleniyor ve gerekli paketler kuruluyor..."
apt update && apt install -y apt-transport-https curl gnupg jq
# Elastic APT deposunu ekle
echo "[*] Elastic GPG anahtarı ekleniyor..."
curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | gpg --
dearmor -o /usr/share/keyrings/elastic.gpg
echo "deb [signed-by=/usr/share/keyrings/elastic.gpg] https://
artifacts.elastic.co/packages/8.x/apt stable main" > /etc/apt/sources.list.d/
elastic-8.x.list
14
apt update
### 2. Elasticsearch Kurulumu
echo "[*] Elasticsearch kuruluyor..."
DEBIAN_FRONTEND=noninteractive apt install -y elasticsearch
# Elasticsearch ayarları: network.host herkese açık, single-node mode
echo "[*] Elasticsearch yapılandırılıyor..."
sed -i 's|#network.host: .*|network.host: 0.0.0.0|' /etc/elasticsearch/
elasticsearch.yml
if ! grep -q "^discovery.type" /etc/elasticsearch/elasticsearch.yml; then
echo "discovery.type: single-node" >> /etc/elasticsearch/elasticsearch.yml
fi
# Elasticsearch servisini başlat
systemctl daemon-reload
systemctl enable elasticsearch
systemctl start elasticsearch
# Elastic kullanıcısı şifresini resetle (random) ve al
echo "[*] Elastic kullanıcı şifresi sıfırlanıyor..."
ELASTIC_PW="$(yes | /usr/share/elasticsearch/bin/elasticsearch-reset-
password -u elastic -s -b 2>/dev/null | awk '/New value:/ {print $NF}')"
echo "Yeni 'elastic' şifresi: $ELASTIC_PW"
# Kibana enrollment token al
echo "[*] Kibana için enrollment token alınıyor..."
KIBANA_TOKEN="$(/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-
token -s kibana)"
echo "Kibana Enrollment Token: $KIBANA_TOKEN"
# (Not: Yukarıdaki token, Kibana'yı elle enroll etmek için kullanılacak.
# Script, Kibana enrollment işlemini otomatik yapmamaktadır.)
### 3. Kibana Kurulumu
echo "[*] Kibana kuruluyor..."
apt install -y kibana
# Kibana yapılandır: dış erişim izni
echo "[*] Kibana yapılandırılıyor..."
sed -i 's|#server.host: .*|server.host: "0.0.0.0"|' /etc/kibana/kibana.yml
# (Opsiyonel) Kibana ile Elastic bağlantısı için elastic kullanıcı bilgisi
ayarı:
# sed -i "s|#elasticsearch.username: .*|elasticsearch.username:
\"elastic\"|" /etc/kibana/kibana.yml
# sed -i "s|#elasticsearch.password: .*|elasticsearch.password:
\"$ELASTIC_PW\"|" /etc/kibana/kibana.yml
systemctl enable kibana
15
# Elasticsearch hazır olana kadar bir süre bekle
echo "[*] Kibana başlamadan önce Elasticsearch servisinin tam başlaması için
bekleniyor..."
sleep 20
systemctl start kibana
echo "Kibana başarılı bir şekilde başlatıldı. İlk kurulum için tarayıcıdan
Kibana'ya erişip enrollment token ve verification code adımlarını
tamamlayın."
echo "Elastic 'elastic' kullanıcı yeni şifresi: $ELASTIC_PW"
### 4. Logstash Kurulumu ve Ayarı
echo "[*] Logstash kuruluyor..."
apt install -y logstash
# Basit bir Logstash pipeline oluştur
cat <<'LSCONF' > /etc/logstash/conf.d/00-siem.conf
input {
beats {
port => 5044
}
udp {
port => 514
type => "syslog"
}
tcp {
port => 514
type => "syslog"
}
}
filter {
if [type] == "syslog" {
grok {
match => { "message" => "<%{NUMBER:priority}>%
{SYSLOGTIMESTAMP:syslog_timestamp} %{HOSTNAME:syslog_hostname} %
{DATA:syslog_program}(?:\\[%{POSINT:syslog_pid}\\])?: %
{GREEDYDATA:syslog_message}" }
}
date {
match => [ "syslog_timestamp", "MMM dd HH:mm:ss", "MMM d HH:mm:ss" ]
}
}
}
output {
elasticsearch {
hosts => ["https://localhost:9200"]
index => "syslog-%{+YYYY.MM.dd}"
user => "elastic"
password => "__ELASTIC_PW__"
ssl => true
16
cacert => "/etc/elasticsearch/certs/http_ca.crt"
}
}
LSCONF
# Elastik şifreyi pipeline'a enjekte et
sed -i "s/__ELASTIC_PW__/$ELASTIC_PW/" /etc/logstash/conf.d/00-siem.conf
# Logstash'i başlat
systemctl enable logstash
systemctl start logstash
echo "Kurulum tamamlandı. Elastic Stack (Elasticsearch, Kibana, Logstash)
çalışır durumda."
echo "Kibana erişimi: https://<SunucuIP>:5601 - Elastic kullanıcı adı:
elastic"
echo "NOT: Kibana ilk açılışta Enrollment Token isteyecektir, yukarıda
üretilen tokenı kullanınız."
Script açık bir şekilde adım adım işlemleri yapmaktadır. Kurulum tamamlandıktan sonra, script çıktısında
elastic kullanıcısı için üretilen yeni şifreyi ve Kibana enrollment token’ını göreceksiniz. Bu token’ı
kullanarak Kibana’yı bağlamak yeterlidir (script Kibana’yı otomatik enroll etmiyor; bunu tarayıcıdan ilk
açılışta yapmanız beklenecek). İsterseniz scriptte Kibana’yı elastic kullanıcıyla bağlama satırlarını (yorum
satırı olarak eklenmiştir) açabilirsiniz ancak güvenlik gereksinimleri nedeniyle enrollment yöntemi
önerilir.
Kaynak: Bu script, Elastic Stack 8.x kurulumunu otomatikleştirme konusunda çevrimiçi
topluluklarda paylaşılan örneklerden esinlenmiştir . Elastic 8 ile gelen şifre ve
token oluşturma komutları kullanılarak kesintisiz bir kurulum akışı sağlanmıştır.
Bu rehberde verilen adımları izleyerek, ajan gerektirmeyen ve tek bir sunucuda toplanan loglara dayalı
bir SIEM kurulumu gerçekleştirdik. Orta ölçekli kurumunuz için temel güvenlik izleme ve alarm üretme
yeteneklerini kazanmış oldunuz. Unutmayın ki SIEM çözümleri sürekli iyileştirme gerektirir: Yeni log
kaynakları eklendikçe parse kurallarını güncellemek, yanlış pozitif üreten kuralları ayarlamak, use-
case’lerinizi geliştirmek önemlidir. Elastic Security, esnek ve güçlü bir platform sunar; MITRE ATT&CK
entegrasyonu ve özelleştirilebilir kural yapısıyla kurumunuzun tehdit algılama olgunluğunu artırmanıza
yardımcı olacaktır.
Kaynakça & İleri Okuma:
Elastic ürün dökümantasyonu – [Elastic Stack 8.x Kurulum Kılavuzu (Ubuntu)]
Elastic Security kullanım kılavuzu – SIEM prebuilt kurallar ve MITRE ATT&CK uyumluluğu
Windows Event Forwarding en iyi uygulamaları – Microsoft Docs & Jessica Payne’in MVA videosu
(özet komutlar)
Kaspersky Security Center SIEM entegrasyonu – Kaspersky Support Kılavuzu (Syslog
yapılandırması)
28 29
• 30 1
• 3 26
•
13 15
•
10 22
17
Install ELK Stack 8.x on Ubuntu 24.04/Ubuntu 22.04 - kifarunix.com
https://kifarunix.com/install-elk-stack-8-x-on-ubuntu/
SIEM with Basic License On-Prem? - SIEM - Discuss the Elastic Stack
https://discuss.elastic.co/t/siem-with-basic-license-on-prem/272109
What can I do with Kibana Alerts with BASIC - FREE AND OPEN 2 subscription? - Kibana - Discuss the
Elastic Stack
https://discuss.elastic.co/t/what-can-i-do-with-kibana-alerts-with-basic-free-and-open-2-subscription/278785
Logstash bind to port 514 - Logstash - Discuss the Elastic Stack
https://discuss.elastic.co/t/logstash-bind-to-port-514/44022
A Practical Guide to Logstash: Syslog Deep Dive - Coralogix
https://coralogix.com/blog/a-practical-guide-to-logstash-syslog-deep-dive/
Configuring SIEM integration settings
https://support.kaspersky.com/ksws/11/en-US/146650.htm
Windows Events, Sysmon and Elk…oh my! (Part 2) - NetSPI
https://www.netspi.com/blog/technical-blog/adversary-simulation/windows-events-sysmon-elk-part-2/
Syslog input | Beats
https://www.elastic.co/docs/reference/beats/filebeat/filebeat-input-syslog
Cisco module | Beats - Elastic
https://www.elastic.co/docs/reference/beats/filebeat/filebeat-module-cisco
The full range of Elastic Security's detection engineering capabilities
https://www.elastic.co/blog/elastic-security-detection-engineering
MITRE ATT&CK® coverage | Elastic Docs
https://www.elastic.co/docs/solutions/security/detect-and-alert/mitre-attandckr-coverage
https://svnscha.de/posts/simplify-elasticsearch-kibana/ · GitHub
https://gist.github.com/svnscha/676291c9e1cdbfa261202b3897afba37
1 2 5 6 7 30
3
4
8
9 11 12
10 21 22 23 24
13 14 15 16 17
18 19
20
25
26 27
28 29
18